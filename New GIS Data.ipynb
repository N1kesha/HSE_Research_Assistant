{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries\n",
    "import archook\n",
    "import arcgis\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "from arcpy import TableToTable_conversion as tt\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "#parameters: VAR identifies regions (used in resulting table)\n",
    "#VAR = \"RegionID\"\n",
    "VAR = \"COUNTRY\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "#setting directories\n",
    "dtb_path = r'C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\FAO SI Data (Tif Files)'\n",
    "weights_path = r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Crops GIS\\crops_suitability\\Global\"\n",
    "tables_path = r'C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices'\n",
    "regions_shape_path = r'C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Crops GIS\\Regions_shp\\Regions.shp'\n",
    "csi_path = r'C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Caloric SI data'\n",
    "countries_shape_path = r'C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Crops GIS\\World_Countries.shp'\n",
    "africa_shape_path = r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\Downloads\\afr_g2014_2013_0\\afr_g2014_2013_0.shp\"\n",
    "hyde_path = r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\HYDE Historical Data\\HYDE Historical Data\"\n",
    "fao_prod_path = r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\FAO Production Data\"\n",
    "trade_path = r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Trade Access Data\\Trade Access Data\"\n",
    "hmi_path = r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Human Mobility Index\\Human Mobility Index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The general part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to convert raster data to numpy arrays (and vice versa)\n",
    "\n",
    "def raster_to_numpy(raster):\n",
    "    descData = arcpy.Describe(raster)\n",
    "    cellSize = descData.meanCellHeight\n",
    "    extent = descData.Extent\n",
    "    spatialReference = descData.spatialReference\n",
    "    pnt = arcpy.Point(extent.XMin,extent.YMin)\n",
    "    return arcpy.RasterToNumPyArray(raster, lower_left_corner=pnt, nodata_to_value=np.nan)\n",
    "\n",
    "def numpy_to_raster(numpy_array):\n",
    "    descData = arcpy.Describe(csi_path + '\\\\' + rasters_csi[0])\n",
    "    cellSize = descData.meanCellHeight\n",
    "    extent = descData.Extent\n",
    "    spatialReference = descData.spatialReference\n",
    "    pnt = arcpy.Point(extent.XMin,extent.YMin)\n",
    "    newRaster = arcpy.NumPyArrayToRaster(numpy_array,pnt,cellSize,cellSize, value_to_nodata = np.nan)\n",
    "    arcpy.DefineProjection_management(newRaster,spatialReference)\n",
    "    return newRaster\n",
    "\n",
    "def raster_to_numpy_0(raster):\n",
    "    descData = arcpy.Describe(raster)\n",
    "    extent = descData.Extent\n",
    "    pnt = arcpy.Point(extent.XMin,extent.YMin)\n",
    "    return arcpy.RasterToNumPyArray(raster, lower_left_corner = pnt, nodata_to_value = 0)\n",
    "\n",
    "def sort_key(e):\n",
    "    return e[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have CSI data on 46 crops.\n"
     ]
    }
   ],
   "source": [
    "# Preparing CSI rasters\n",
    "\n",
    "env.workspace = csi_path\n",
    "rasters_raw = arcpy.ListRasters()\n",
    "rasters_csi = []\n",
    "for i in rasters_raw:\n",
    "    if 'lo' in i: \n",
    "        rasters_csi.append(i)\n",
    "print(f'We have CSI data on {len(rasters_csi)} crops.')\n",
    "\n",
    "\n",
    "# Making np.arrays with CSI data for all crops\n",
    "\n",
    "rasters_csi_np = []\n",
    "for n in range(46):\n",
    "    rasters_csi_np.append(raster_to_numpy(rasters_csi[n]))\n",
    "    \n",
    "rasters_csi_np_0 = []\n",
    "for n in range(46):\n",
    "    rasters_csi_np_0.append(raster_to_numpy_0(rasters_csi[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have SI data on 46 crops.\n"
     ]
    }
   ],
   "source": [
    "# Preparing SI rasters\n",
    "\n",
    "env.workspace = dtb_path\n",
    "rasters_raw = arcpy.ListRasters()\n",
    "rasters_si0 = []\n",
    "for raster in rasters_raw:\n",
    "    if 'sxLr0_' in raster:\n",
    "        rasters_si0.append(raster.replace(\"sxLr0_\", \"\"))\n",
    "rasters_si = []\n",
    "for raster in rasters_si0:\n",
    "    rasters_si.append(\"sxLr0_\" + raster)\n",
    "    \n",
    "\n",
    "    \n",
    "rasters_si = sorted(rasters_si)\n",
    "rasters_si[2], rasters_si[3] = rasters_si[3], rasters_si[2] \n",
    "rasters_si.insert(6, rasters_si[12])\n",
    "del rasters_si[13]\n",
    "rasters_si[15], rasters_si[16] = rasters_si[16], rasters_si[15] \n",
    "rasters_si.insert(17, rasters_si[28])\n",
    "rasters_si[19], rasters_si[20] = rasters_si[20], rasters_si[19]\n",
    "del rasters_si[29]\n",
    "rasters_si[26], rasters_si[27] = rasters_si[27], rasters_si[26] \n",
    "rasters_si[26], rasters_si[28] = rasters_si[28], rasters_si[26] \n",
    "rasters_si[29], rasters_si[30] = rasters_si[30], rasters_si[29]\n",
    "rasters_si[29], rasters_si[31] = rasters_si[31], rasters_si[29]\n",
    "rasters_si[33], rasters_si[36] = rasters_si[36], rasters_si[33] \n",
    "rasters_si[35], rasters_si[37] = rasters_si[37], rasters_si[35] \n",
    "rasters_si[36], rasters_si[38] = rasters_si[38], rasters_si[36] \n",
    "rasters_si[37], rasters_si[38] = rasters_si[38], rasters_si[37] \n",
    "\n",
    "print(f'We have SI data on {len(rasters_si)} crops.')\n",
    "\n",
    "\n",
    "\n",
    "rasters_si_np = []\n",
    "for n in range(46):\n",
    "    rasters_si_np.append(raster_to_numpy(Float(rasters_si[n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alfalfalo.tif': 'sxLr0_alf_Alfalfa.tif',\n",
       " 'bananalo.tif': 'sxLr0_ban_Banana.tif',\n",
       " 'barleylo.tif': 'sxLr0_brl_Barley.tif',\n",
       " 'buckwheatlo.tif': 'sxLr0_bck_Buckwheat.tif',\n",
       " 'cabbagelo.tif': 'sxLr0_cab_Cabbage.tif',\n",
       " 'carrotlo.tif': 'sxLr0_car_Carrot.tif',\n",
       " 'cassavalo.tif': 'sxLr0_csv_Cassava.tif',\n",
       " 'chickpealo.tif': 'sxLr0_chk_Chickpea.tif',\n",
       " 'citruslo.tif': 'sxLr0_cit_Citrus.tif',\n",
       " 'coconutlo.tif': 'sxLr0_coc_Coconut.tif',\n",
       " 'coffeelo.tif': 'sxLr0_cof_Coffee.tif',\n",
       " 'cottonlo.tif': 'sxLr0_cot_Cotton.tif',\n",
       " 'cowpealo.tif': 'sxLr0_cow_Cowpea.tif',\n",
       " 'flaxlo.tif': 'sxLr0_flx_Flax.tif',\n",
       " 'foxtailmilletlo.tif': 'sxLr0_fml_FoxtailMillet.tif',\n",
       " 'gramlo.tif': 'sxLr0_grm_Gram.tif',\n",
       " 'groundnutlo.tif': 'sxLr0_grd_Groundnut.tif',\n",
       " 'indricelo.tif': 'sxLr0_rcd_DrylandRice.tif',\n",
       " 'jatrophalo.tif': 'sxLr0_jtr_Jatropha.tif',\n",
       " 'maizelo.tif': 'sxLr0_mze_Maize.tif',\n",
       " 'miscanthuslo.tif': 'sxLr0_mis_Miscanthus.tif',\n",
       " 'oatlo.tif': 'sxLr0_oat_Oat.tif',\n",
       " 'oilpalmlo.tif': 'sxLr0_olp_OilPalm.tif',\n",
       " 'olivelo.tif': 'sxLr0_olv_Olive.tif',\n",
       " 'onionlo.tif': 'sxLr0_oni_Onion.tif',\n",
       " 'pealo.tif': 'sxLr0_pea_DryPea.tif',\n",
       " 'pearlmilletlo.tif': 'sxLr0_pml_PearlMillet.tif',\n",
       " 'phaseolusbeanlo.tif': 'sxLr0_phb_PhaseolusBean.tif',\n",
       " 'pigeonpealo.tif': 'sxLr0_pig_Pigeonpea.tif',\n",
       " 'rapeseedlo.tif': 'sxLr0_rsd_Rapeseed.tif',\n",
       " 'reedcanarygrasslo.tif': 'sxLr0_rcg_ReedCanaryGrass.tif',\n",
       " 'ricewetlo.tif': 'sxLr0_rcw_WetlandRice.tif',\n",
       " 'ryelo.tif': 'sxLr0_rye_Rye.tif',\n",
       " 'sorghumlo.tif': 'sxLr0_srg_Sorghim.tif',\n",
       " 'soybeanlo.tif': 'sxLr0_soy_Soybean.tif',\n",
       " 'sugarbeetlo.tif': 'sxLr0_sub_Sugarbeet.tif',\n",
       " 'sugarcanelo.tif': 'sxLr0_suc_Sugarcane.tif',\n",
       " 'sunflowerlo.tif': 'sxLr0_sfl_Sunflower.tif',\n",
       " 'sweetpotatolo.tif': 'sxLr0_spo_SweetPotato.tif',\n",
       " 'switchgrasslo.tif': 'sxLr0_swg_SwitchGrass.tif',\n",
       " 'tealo.tif': 'sxLr0_tea_Tea.tif',\n",
       " 'tobaccolo.tif': 'sxLr0_tob_Tobacco.tif',\n",
       " 'tomatolo.tif': 'sxLr0_tom_Tomato.tif',\n",
       " 'wheatlo.tif': 'sxLr0_whe_Wheat.tif',\n",
       " 'whitepotatolo.tif': 'sxLr0_wpo_WhitePotato.tif',\n",
       " 'yamlo.tif': 'sxLr0_yam_Yam.tif'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the matching of CSI and SI raster files\n",
    "\n",
    "dict(zip(rasters_csi, rasters_si))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_dict = {'alfalfalo.tif': 'alf','bananalo.tif': 'ban','barleylo.tif': 'brl','buckwheatlo.tif': 'bck','cabbagelo.tif': 'cab','carrotlo.tif': 'car','cassavalo.tif': 'csv','chickpealo.tif': 'chk','citruslo.tif': 'cit',\n",
    " 'coconutlo.tif': 'cocn',\n",
    " 'coffeelo.tif': 'cof',\n",
    " 'cottonlo.tif': 'cot',\n",
    " 'cowpealo.tif': 'cow',\n",
    " 'flaxlo.tif': 'flx',\n",
    " 'foxtailmilletlo.tif': 'fml',\n",
    " 'gramlo.tif': 'grm',\n",
    " 'groundnutlo.tif': 'grd',\n",
    " 'indricelo.tif': 'rcd',\n",
    " 'jatrophalo.tif': 'jtr',\n",
    " 'maizelo.tif': 'mze',\n",
    " 'miscanthuslo.tif': 'mis',\n",
    " 'oatlo.tif': 'oat',\n",
    " 'oilpalmlo.tif': 'olp',\n",
    " 'olivelo.tif': 'olv',\n",
    " 'onionlo.tif': 'oni',\n",
    " 'pealo.tif': 'pea',\n",
    " 'pearlmilletlo.tif': 'pml',\n",
    " 'phaseolusbeanlo.tif': 'phb',\n",
    " 'pigeonpealo.tif': 'pig',\n",
    " 'rapeseedlo.tif': 'rsd',\n",
    " 'reedcanarygrasslo.tif': 'rcg',\n",
    " 'ricewetlo.tif': 'rcw',\n",
    " 'ryelo.tif': 'rye',\n",
    " 'sorghumlo.tif': 'srg',\n",
    " 'soybeanlo.tif': 'soy',\n",
    " 'sugarbeetlo.tif': 'sub',\n",
    " 'sugarcanelo.tif': 'suc',\n",
    " 'sunflowerlo.tif': 'sfl',\n",
    " 'sweetpotatolo.tif': 'spo',\n",
    " 'switchgrasslo.tif': 'swg',\n",
    " 'tealo.tif': 'tea',\n",
    " 'tobaccolo.tif': 'tob',\n",
    " 'tomatolo.tif': 'tom',\n",
    " 'wheatlo.tif': 'whe',\n",
    " 'whitepotatolo.tif': 'wpo',\n",
    " 'yamlo.tif': 'yam'}\n",
    "\n",
    "crops_dict = dict(zip(crops_dict.values(), crops_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have HYDE data on 16 files.\n"
     ]
    }
   ],
   "source": [
    "# Preparing HYDE rasters\n",
    "\n",
    "env.workspace = hyde_path\n",
    "rasters_raw = arcpy.ListRasters()\n",
    "rasters_hyde = []\n",
    "for i in rasters_raw:\n",
    "    if \"AD.asc.tif\" in i: \n",
    "        rasters_hyde.append(i)\n",
    "print(f'We have HYDE data on {len(rasters_hyde)} files.')\n",
    "\n",
    "for raster in rasters_hyde:\n",
    "    descData = arcpy.Describe(dtb_path + '\\\\' + rasters_si[0])\n",
    "    spatialReference = descData.spatialReference\n",
    "    arcpy.DefineProjection_management(raster,spatialReference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have FAO Production data on 27 crops.\n"
     ]
    }
   ],
   "source": [
    "# Preparing FAO Production rasters\n",
    "\n",
    "env.workspace = fao_prod_path\n",
    "rasters_raw = arcpy.ListRasters()\n",
    "rasters_fao_prod = []\n",
    "for i in rasters_raw:\n",
    "    if \"2000\" in i: \n",
    "        rasters_fao_prod.append(i)\n",
    "print(f'We have FAO Production data on {len(rasters_fao_prod)} crops.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing SI and CSI rasters for PRE1500\n",
    "\n",
    "regions_pre1500 = pd.read_excel(tables_path + '\\\\FAO_CropAvailability_Pre1500.xlsx', sheet_name='Regions')\n",
    "crops_pre1500 = pd.read_excel(tables_path + '\\\\FAO_CropAvailability_Pre1500.xlsx', sheet_name='Crops')\n",
    "crops_pre1500 = crops_pre1500.iloc[:, 0:12]\n",
    "regions_pre1500 = regions_pre1500.iloc[:, 0:8]\n",
    "\n",
    "saf_crops = list(crops_pre1500[crops_pre1500['Subsaharan Africa']==1]['code'])\n",
    "naf_crops = list(crops_pre1500[crops_pre1500['North Africa']==1]['code'])\n",
    "eu_crops = list(crops_pre1500[crops_pre1500['Europe']==1]['code'])\n",
    "asia_crops = list(crops_pre1500[crops_pre1500['Asia']==1]['code'])\n",
    "oceania_crops = list(crops_pre1500[crops_pre1500['Oceania']==1]['code'])\n",
    "america_crops = list(crops_pre1500[crops_pre1500['America']==1]['code'])\n",
    "\n",
    "saf_rasters_csi = []\n",
    "naf_rasters_csi = []\n",
    "eu_rasters_csi = []\n",
    "asia_rasters_csi = []\n",
    "oceania_rasters_csi = []\n",
    "america_rasters_csi = []\n",
    "\n",
    "for crop in saf_crops:\n",
    "    saf_rasters_csi.append(crops_dict[crop])\n",
    "for crop in naf_crops:\n",
    "    naf_rasters_csi.append(crops_dict[crop])\n",
    "for crop in eu_crops:\n",
    "    eu_rasters_csi.append(crops_dict[crop])\n",
    "for crop in asia_crops:\n",
    "    asia_rasters_csi.append(crops_dict[crop])\n",
    "for crop in oceania_crops:\n",
    "    oceania_rasters_csi.append(crops_dict[crop])\n",
    "for crop in america_crops:\n",
    "    america_rasters_csi.append(crops_dict[crop])\n",
    "\n",
    "dict_names = dict(zip(rasters_csi, rasters_si))\n",
    "\n",
    "saf_rasters_si = []\n",
    "naf_rasters_si = []\n",
    "eu_rasters_si = []\n",
    "asia_rasters_si = []\n",
    "oceania_rasters_si = []\n",
    "america_rasters_si = []\n",
    "\n",
    "for crop in saf_rasters_csi:\n",
    "    saf_rasters_si.append(dict_names[crop])\n",
    "for crop in naf_rasters_csi:\n",
    "    naf_rasters_si.append(dict_names[crop])\n",
    "for crop in eu_rasters_csi:\n",
    "    eu_rasters_si.append(dict_names[crop])\n",
    "for crop in asia_rasters_csi:\n",
    "    asia_rasters_si.append(dict_names[crop])\n",
    "for crop in oceania_rasters_csi:\n",
    "    oceania_rasters_si.append(dict_names[crop])\n",
    "for crop in america_rasters_csi:\n",
    "    america_rasters_si.append(dict_names[crop])\n",
    "\n",
    "    \n",
    "fc = regions_shape_path\n",
    "fields = ['RegionID', 'COUNTRY']\n",
    "res = []\n",
    "with arcpy.da.SearchCursor(fc, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        res.append(row)\n",
    "ccodes = pd.DataFrame(res, columns = ['REGIONID', \"COUNTRY\"])\n",
    "ccodes.loc[ccodes[\"COUNTRY\"] == \"Côte d'Ivoire\", \"COUNTRY\"] = \"C_te d'Ivoire\"\n",
    "ccodes.loc[ccodes[\"COUNTRY\"] == \"São Tomé and Príncipe\", \"COUNTRY\"] = \"S_o Tom_ and Pr_ncipe\"\n",
    "regions_pre1500 = regions_pre1500.merge(ccodes, left_on='rcode', right_on='REGIONID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:18<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating indicator-rasters for all crops which show whether SI in the specific cell is higher than 0.1 cutoff or not\n",
    "\n",
    "env.workspace = dtb_path\n",
    "\n",
    "rasters_si_ind_np = []\n",
    "for i in tqdm(range(46)):\n",
    "    rasters_si_ind_np.append((raster_to_numpy(Float(rasters_si[i]))>=1000)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DevEc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = dtb_path\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_si, 'MEAN', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(africa_shape_path, \"ADM0_NAME\", out,\n",
    "                        r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\Downloads\\RESULTS\", \"DATA\", \"ALL\")\n",
    "tt(r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\Downloads\\RESULTS\", r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\Downloads\", 'Africa_si.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = csi_path\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'MEAN', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(africa_shape_path, \"ADM0_NAME\", out,\n",
    "                        r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\Downloads\\RESULTS\", \"DATA\", \"ALL\")\n",
    "tt(r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\Downloads\\RESULTS\", r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\Downloads\", 'Africa_csi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New indices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = csi_path\n",
    "\n",
    "# Defining maximum CSI in each cell\n",
    "csi_max_among_all_cell = Float(arcpy.sa.CellStatistics(rasters_csi, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "# Avoiding cells where maximum CSI = 0\n",
    "csi_max_among_all_cells = SetNull(csi_max_among_all_cell, csi_max_among_all_cell, \"VALUE <= 0\")\n",
    "csi_max_among_all_cells.save(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's make an indicator for each cell which shows wheather a concrete crop's CSI equals to maximum CSI \n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = EqualTo(raster, csi_max_among_all_cells)\n",
    "    Float(out).save(tables_path + '\\\\A1\\\\A1_1\\\\csi_max_ind\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Making np.arrays with indicators of max CSI for all crops \n",
    "\n",
    "env.workspace = tables_path + '\\\\A1\\\\A1_1\\\\csi_max_ind'\n",
    "\n",
    "all_crops_np = []\n",
    "for i in range(46):\n",
    "    all_crops_np.append(raster_to_numpy(rasters_csi[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Checking if there are few cells of different crops which equal to maximum CSI\n",
    "\n",
    "overlay = np.zeros((2160, 4320)) \n",
    "for i in range(46):\n",
    "    overlay = overlay + all_crops_np[i]\n",
    "\n",
    "np.unique(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fixing indicators of representing maximum CSI \n",
    "\n",
    "double_overlay = np.argwhere(overlay==2)\n",
    "for i in range(46):\n",
    "    for j in range(double_overlay.shape[0]):\n",
    "        if all_crops_np[i][double_overlay[j][0]][double_overlay[j][1]] == 1:\n",
    "            all_crops_np[i][double_overlay[j][0]][double_overlay[j][1]] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Just checking the correctness of the received result\n",
    "\n",
    "final = np.zeros((2160, 4320)) \n",
    "for i in range(46):\n",
    "    final = final + all_crops_np[i]\n",
    "    \n",
    "print(np.argwhere(final>1))\n",
    "\n",
    "# The list must be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Saving the final version of indicators of representing maximum CSI for all crops\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = numpy_to_raster(all_crops_np[i])\n",
    "    out.save(tables_path + '\\\\A1\\\\A1_1\\\\csi_max_ind\\\\' + rasters_csi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [25:46<00:00, 33.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the share of cells for which crop c is optimal across regions (for all crops)\n",
    "# Takes 30 min to compute\n",
    "\n",
    "env.workspace = tables_path + '\\\\A1\\\\A1_1\\\\csi_max_ind'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A1\\\\A1_1\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:29<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A1\\\\A1_1\\\\share'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A1\\\\A1_1\\\\share_squared\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A1_1_READY.csv<h2>Messages</h2>Start Time: 3 июня 2023 г. 14:18:21<br/>Succeeded at 3 июня 2023 г. 14:18:22 (Elapsed Time: 0,09 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A1_1_READY.csv'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A1\\\\A1_1\\\\share_squared'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +\"\\\\A1\\\\A1_1\\\\RESULTS\", \"DATA\", \"MINIMUM\")\n",
    "tt(tables_path +\"\\\\A1\\\\A1_1\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A1_1_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'continent' is one word from set(\"saf\", \"naf\", \"eu\", \"asia\", \"oceania\", \"america\") \n",
    "\n",
    "def computing_A1_2(rasters_csi, continent):\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    # Defining maximum CSI in each cell\n",
    "    csi_max_among_all_cell = Float(arcpy.sa.CellStatistics(rasters_csi, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "    # Avoiding cells where maximum CSI = 0\n",
    "    csi_max_among_all_cells = SetNull(csi_max_among_all_cell, csi_max_among_all_cell, \"VALUE <= 0\")\n",
    "    csi_max_among_all_cells.save(tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\csi_max')\n",
    "\n",
    "    # Let's make an indicator for each cell which shows wheather a concrete crop's CSI equals to maximum CSI \n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = EqualTo(raster, csi_max_among_all_cells)\n",
    "        Float(out).save(tables_path + '\\\\A1\\\\A1_2\\\\' + continent +  '\\\\csi_max_ind\\\\' + raster)\n",
    "        \n",
    "    # Making np.arrays with indicators of max CSI for all crops \n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_2\\\\' + continent +  '\\\\csi_max_ind'\n",
    "\n",
    "    all_crops_np = []\n",
    "    for i in range(len(rasters_csi)):\n",
    "        all_crops_np.append(raster_to_numpy(rasters_csi[i]))\n",
    "        \n",
    "    # Checking if there are few cells of different crops which equal to maximum CSI\n",
    "\n",
    "    overlay = np.zeros((2160, 4320)) \n",
    "    for i in range(len(rasters_csi)):\n",
    "        overlay = overlay + all_crops_np[i]\n",
    "        \n",
    "    # Fixing indicators of representing maximum CSI \n",
    "\n",
    "    double_overlay = np.argwhere(overlay==2)\n",
    "    for i in range(len(rasters_csi)):\n",
    "        for j in range(double_overlay.shape[0]):\n",
    "            if all_crops_np[i][double_overlay[j][0]][double_overlay[j][1]] == 1:\n",
    "                all_crops_np[i][double_overlay[j][0]][double_overlay[j][1]] = 0.5\n",
    "                \n",
    "    # Saving the final version of indicators of representing maximum CSI for all crops\n",
    "\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        out = numpy_to_raster(all_crops_np[i])\n",
    "        out.save(tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\csi_max_ind\\\\' + rasters_csi[i])\n",
    "        \n",
    "    # Calculating the share of cells for which crop c is optimal across regions (for all crops)\n",
    "    \n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\csi_max_ind'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "        \n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "        \n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\share_squared'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MINIMUM\")\n",
    "    tt(tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A1_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A1_2(rasters_csi, continent):\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\csi_max_ind'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "        \n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "        \n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\share_squared'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MINIMUM\")\n",
    "    tt(tables_path + '\\\\A1\\\\A1_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A1_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:44<00:00, 31.31s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_2(rasters_csi = saf_rasters_csi, continent = 'saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [09:46<00:00, 32.56s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:07<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_2(rasters_csi = naf_rasters_csi, continent = 'naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [09:21<00:00, 33.01s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:07<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_2(rasters_csi = eu_rasters_csi, continent = 'eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [15:38<00:00, 34.76s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:10<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_2(rasters_csi = asia_rasters_csi, continent = 'asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:29<00:00, 29.89s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_2(rasters_csi = oceania_rasters_csi, continent = 'oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [07:12<00:00, 30.90s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_2(rasters_csi = america_rasters_csi, continent = 'america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then I manually renamed columns with computed indeces in resuting tables (from 'MIN' to 'continent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_2_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_2_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_2_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_2_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_2_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_2_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A1_2'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A1_2']].to_excel(tables_path + '\\\\READY_country_level\\\\A1_2_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating CSI rasters which satisfy both constraints:\n",
    "# 1) max SI across all crops >= 0.1 (suitable cell for agriculture)\n",
    "# 2) SI of the optimal crop >= 0.1 (suitable crop for growing)\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = Con(dtb_path + '\\\\' + rasters_si[i], 1, 0, \"VALUE >= 1000\") * Raster(csi_path + '\\\\' + rasters_csi[i]) * Raster(cutoff_constraint)\n",
    "    Float(out).save(tables_path + '\\\\A1\\\\A1_3\\\\rastersXind\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\A1\\\\A1_3\\\\rastersXind'\n",
    "\n",
    "# Defining maximum CSI in each cell\n",
    "csi_max_among_all_cell = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "# Avoiding cells where maximum CSI = 0\n",
    "csi_max_among_all_cells = SetNull(csi_max_among_all_cell, csi_max_among_all_cell, \"VALUE <= 0\")\n",
    "csi_max_among_all_cells.save(tables_path + '\\\\A1\\\\A1_3\\\\csi_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's make an indicator for each cell which shows wheather a concrete crop's CSI equals to maximum CSI \n",
    "\n",
    "for raster in tqdm(rasters_si):\n",
    "    out = EqualTo(raster, csi_max_among_all_cells)\n",
    "    Float(out).save(tables_path + '\\\\A1\\\\A1_3\\\\csi_max_ind\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Making np.arrays with indicators of max CSI for all crops \n",
    "\n",
    "env.workspace = tables_path + '\\\\A1\\\\A1_3\\\\csi_max_ind'\n",
    "\n",
    "all_crops_np = []\n",
    "for i in range(46):\n",
    "    all_crops_np.append(raster_to_numpy(rasters_si[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Checking if there are few cells of different crops which equal to maximum CSI\n",
    "\n",
    "overlay = np.zeros((2160, 4320)) \n",
    "for i in range(46):\n",
    "    overlay = overlay + all_crops_np[i]\n",
    "\n",
    "np.unique(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fixing indicators of representing maximum CSI \n",
    "\n",
    "double_overlay = np.argwhere(overlay==2)\n",
    "for i in range(46):\n",
    "    for j in range(double_overlay.shape[0]):\n",
    "        if all_crops_np[i][double_overlay[j][0]][double_overlay[j][1]] == 1:\n",
    "            all_crops_np[i][double_overlay[j][0]][double_overlay[j][1]] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Just checking the correctness of the received result\n",
    "\n",
    "final = np.zeros((2160, 4320)) \n",
    "for i in range(46):\n",
    "    final = final + all_crops_np[i]\n",
    "    \n",
    "print(np.argwhere(final>1))\n",
    "\n",
    "# The list must be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Saving the final version of indicators of representing maximum CSI for all crops\n",
    "\n",
    "env.workspace = tables_path + '\\\\A1\\\\A1_3\\\\csi_max_ind'\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = numpy_to_raster(all_crops_np[i])\n",
    "    out.save(tables_path + '\\\\A1\\\\A1_3\\\\csi_max_ind\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [29:55<00:00, 39.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the share of cells for which crop c is optimal across regions (for all crops)\n",
    "# Takes 30 min to compute\n",
    "\n",
    "env.workspace = tables_path + '\\\\A1\\\\A1_3\\\\csi_max_ind'\n",
    "\n",
    "for raster in tqdm(rasters_si):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A1\\\\A1_3\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:19<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A1\\\\A1_3\\\\share'\n",
    "\n",
    "for raster in tqdm(rasters_si):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A1\\\\A1_3\\\\share_squared\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A1_3_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 17:51:28<br/>Succeeded at 5 июня 2023 г. 17:51:28 (Elapsed Time: 0,11 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A1_3_READY.csv'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A1\\\\A1_3\\\\share_squared'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_si, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +\"\\\\A1\\\\A1_3\\\\RESULTS\", \"DATA\", \"MINIMUM\")\n",
    "tt(tables_path +\"\\\\A1\\\\A1_3\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A1_3_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A1_4(rasters_csi, rasters_si, continent):\n",
    "    \n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    # Defining maximum SI in each cell\n",
    "    max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "    # Avoiding cells where maximum SI <= 0.1\n",
    "    cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "\n",
    "    # Creating CSI rasters which satisfy both constraints:\n",
    "    # 1) max SI across all crops >= 0.1 (suitable cell for agriculture)\n",
    "    # 2) SI of the optimal crop >= 0.1 (suitable crop for growing)\n",
    "\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        out = Con(dtb_path + '\\\\' + rasters_si[i], 1, 0, \"VALUE >= 1000\") * Raster(csi_path + '\\\\' + rasters_csi[i]) * Raster(cutoff_constraint)\n",
    "        Float(out).save(tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\rastersXind\\\\' + rasters_si[i])\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\rastersXind'\n",
    "    \n",
    "    # Defining maximum CSI in each cell\n",
    "    csi_max_among_all_cell = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "    # Avoiding cells where maximum CSI = 0\n",
    "    csi_max_among_all_cells = SetNull(csi_max_among_all_cell, csi_max_among_all_cell, \"VALUE <= 0\")\n",
    "    csi_max_among_all_cells.save(tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\csi_max')\n",
    "\n",
    "    # Let's make an indicator for each cell which shows wheather a concrete crop's CSI equals to maximum CSI \n",
    "\n",
    "    for raster in tqdm(rasters_si):\n",
    "        out = EqualTo(raster, csi_max_among_all_cells)\n",
    "        Float(out).save(tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\csi_max_ind\\\\' + raster)\n",
    "\n",
    "    # Making np.arrays with indicators of max CSI for all crops \n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\csi_max_ind'\n",
    "\n",
    "    all_crops_np = []\n",
    "    for i in range(len(rasters_si)):\n",
    "        all_crops_np.append(raster_to_numpy(rasters_si[i]))\n",
    "\n",
    "    # Checking if there are few cells of different crops which equal to maximum CSI\n",
    "\n",
    "    overlay = np.zeros((2160, 4320)) \n",
    "    for i in range(len(rasters_si)):\n",
    "        overlay = overlay + all_crops_np[i]\n",
    "\n",
    "    # Fixing indicators of representing maximum CSI \n",
    "\n",
    "    double_overlay = np.argwhere(overlay==2)\n",
    "    for i in range(len(rasters_si)):\n",
    "        for j in range(double_overlay.shape[0]):\n",
    "            if all_crops_np[i][double_overlay[j][0]][double_overlay[j][1]] == 1:\n",
    "                all_crops_np[i][double_overlay[j][0]][double_overlay[j][1]] = 0.5\n",
    "\n",
    "    # Saving the final version of indicators of representing maximum CSI for all crops\n",
    "\n",
    "    for i in tqdm(range(len(rasters_si))):\n",
    "        out = numpy_to_raster(all_crops_np[i])\n",
    "        out.save(tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\csi_max_ind\\\\' + rasters_si[i])\n",
    "\n",
    "    # Calculating the share of cells for which crop c is optimal across regions (for all crops)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\csi_max_ind'\n",
    "\n",
    "    for raster in tqdm(rasters_si):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_si):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_si, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +\"\\\\A1\\\\A1_4\\\\\" + continent + \"\\\\RESULTS\", \"DATA\", \"MINIMUM\")\n",
    "    tt(tables_path +\"\\\\A1\\\\A1_4\\\\\" + continent + \"\\\\RESULTS\", tables_path + '\\\\READY', 'A1_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A1_4(rasters_csi, rasters_si, continent):\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\csi_max_ind'\n",
    "\n",
    "    for raster in tqdm(rasters_si):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_si):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A1\\\\A1_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_si, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +\"\\\\A1\\\\A1_4\\\\\" + continent + \"\\\\RESULTS\", \"DATA\", \"MINIMUM\")\n",
    "    tt(tables_path +\"\\\\A1\\\\A1_4\\\\\" + continent + \"\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A1_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:03<00:00, 27.56s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_4(rasters_csi = saf_rasters_csi, rasters_si = saf_rasters_si, continent = 'saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:11<00:00, 27.31s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_4(rasters_csi = naf_rasters_csi, rasters_si = naf_rasters_si, continent = 'naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [08:00<00:00, 28.24s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_4(rasters_csi = eu_rasters_csi, rasters_si = eu_rasters_si, continent = 'eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:27<00:00, 27.69s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:10<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_4(rasters_csi = asia_rasters_csi, rasters_si = asia_rasters_si, continent = 'asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:23<00:00, 27.41s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:04<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_4(rasters_csi = america_rasters_csi, rasters_si = america_rasters_si, continent = 'america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:27<00:00, 29.08s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A1_4(rasters_csi = oceania_rasters_csi, rasters_si = oceania_rasters_si, continent = 'oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then I manually renamed columns with computed indeces in resuting tables (from 'MIN' to 'continent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_4_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_4_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_4_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_4_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_4_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A1_4_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MIN\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A1_4'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A1_4']].to_excel(tables_path + '\\\\READY_country_level\\\\A1_4_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A2a_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Finding out which crops make the TOP 3 in each cell\n",
    "# Takes 15 min to compute\n",
    "\n",
    "top3_crops_num = np.zeros((2160, 4320))\n",
    "top3_crops_num = pd.DataFrame(top3_crops_num)\n",
    "top3_crops_num = top3_crops_num.astype(object)\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        my_list = []\n",
    "        for n in range(46):\n",
    "            if rasters_csi_np_0[n][i][j] != 0:\n",
    "                my_list.append((n, rasters_csi_np_0[n][i][j]))\n",
    "        my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "        if len(my_list)>=3:\n",
    "            top3_crops_num[j][i] = [my_list[:3][k][0] for k in range(3)]\n",
    "\n",
    "        \n",
    "# In top3_crops_num, 0 means that there are no TOP 3 crops in the cell\n",
    "# [a, c, b] means that crops by these ordinal numbers make the TOP 3 in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing indicators of representing TOP 3 crops in each cell \n",
    "\n",
    "top3_ind = np.zeros((46, 2160, 4320))\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if top3_crops_num[j][i] != 0:\n",
    "            top3_ind[top3_crops_num[j][i][0]][i][j] = 1/3\n",
    "            top3_ind[top3_crops_num[j][i][1]][i][j] = 1/3 \n",
    "            top3_ind[top3_crops_num[j][i][2]][i][j] = 1/3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "top3_crops_num_copy = top3_crops_num.copy()\n",
    "top3_crops_num_copy = (top3_crops_num_copy == 0)*1\n",
    "x = top3_crops_num_copy.astype('float64')\n",
    "x = x.to_numpy()\n",
    "\n",
    "for i in range(2160):\n",
    "    for j in range(4320):\n",
    "        if x[i][j]==1:\n",
    "            x[i][j]=np.nan\n",
    "        else: \n",
    "            x[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "for i in range(46):\n",
    "    top3_ind[i] = x * top3_ind[i]\n",
    "\n",
    "# Saving indeces of representing TOP 3 crops in each cell \n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = numpy_to_raster(top3_ind[i])\n",
    "    out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_1\\\\csi_top3_ind\\\\' + rasters_csi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [28:45<00:00, 37.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "# Takes 30 min to compute\n",
    "\n",
    "env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_1\\\\csi_top3_ind'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_1\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:40<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_1\\\\share'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_1\\\\share_squared\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A2a_1_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 18:24:40<br/>Succeeded at 5 июня 2023 г. 18:24:41 (Elapsed Time: 0,09 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A2a_1_READY.csv'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_1\\\\share_squared'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +\"\\\\A2\\\\top3crops\\\\A2_1\\\\RESULTS\", \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +\"\\\\A2\\\\top3crops\\\\A2_1\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A2a_1_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A2a_2(rasters_csi, continent):\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    rasters_csi_np_0 = []\n",
    "    for n in range(len(rasters_csi)):\n",
    "        rasters_csi_np_0.append(raster_to_numpy_0(rasters_csi[n]))\n",
    "\n",
    "    # Finding out which crops make the TOP 3 in each cell\n",
    "\n",
    "    top3_crops_num = np.zeros((2160, 4320))\n",
    "    top3_crops_num = pd.DataFrame(top3_crops_num)\n",
    "    top3_crops_num = top3_crops_num.astype(object)\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            my_list = []\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if rasters_csi_np_0[n][i][j] != 0:\n",
    "                    my_list.append((n, rasters_csi_np_0[n][i][j]))\n",
    "            my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "            if len(my_list)>=3:\n",
    "                top3_crops_num[j][i] = [my_list[:3][k][0] for k in range(3)]\n",
    "\n",
    "    # Computing indicators of representing TOP 3 crops in each cell \n",
    "\n",
    "    top3_ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if top3_crops_num[j][i] != 0:\n",
    "                top3_ind[top3_crops_num[j][i][0]][i][j] = 1/3\n",
    "                top3_ind[top3_crops_num[j][i][1]][i][j] = 1/3 \n",
    "                top3_ind[top3_crops_num[j][i][2]][i][j] = 1/3 \n",
    "\n",
    "\n",
    "    # Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "    top3_crops_num_copy = top3_crops_num.copy()\n",
    "    top3_crops_num_copy = (top3_crops_num_copy == 0)*1\n",
    "    x = top3_crops_num_copy.astype('float64')\n",
    "    x = x.to_numpy()\n",
    "\n",
    "    for i in range(2160):\n",
    "        for j in range(4320):\n",
    "            if x[i][j]==1:\n",
    "                x[i][j]=np.nan\n",
    "            else: \n",
    "                x[i][j]=1\n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    for i in range(len(rasters_csi)):\n",
    "        top3_ind[i] = x * top3_ind[i]\n",
    "\n",
    "    # Saving indeces of representing TOP 3 crops in each cell \n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        out = numpy_to_raster(top3_ind[i])\n",
    "        out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\csi_top3_ind\\\\' + rasters_csi[i])\n",
    "\n",
    "\n",
    "    # Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\csi_top3_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\'+ continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\'+ continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\share_squared'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A2a_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A2a_2(rasters_csi, continent):\n",
    "    \n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\csi_top3_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\'+ continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\'+ continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\share_squared'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A2\\\\top3crops\\\\A2_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A2a_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:18<00:00, 28.99s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:03<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_2(rasters_csi=saf_rasters_csi, continent='saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:05<00:00, 26.99s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_2(rasters_csi=naf_rasters_csi, continent='naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:20<00:00, 27.41s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:12<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_2(rasters_csi=asia_rasters_csi, continent='asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [08:25<00:00, 29.71s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_2(rasters_csi=eu_rasters_csi, continent='eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:40<00:00, 28.61s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:04<00:00,  3.15it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_2(rasters_csi=america_rasters_csi, continent='america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:20<00:00, 26.76s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.41it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_2(rasters_csi=oceania_rasters_csi, continent='oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_2_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_2_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_2_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_2_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_2_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_2_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A2a_2'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A2a_2']].to_excel(tables_path + '\\\\READY_country_level\\\\A2a_2_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A2a_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Finding out which crops make the TOP 3 in each cell\n",
    "\n",
    "top3_crops_num = np.zeros((2160, 4320))\n",
    "top3_crops_num = pd.DataFrame(top3_crops_num)\n",
    "top3_crops_num = top3_crops_num.astype(object)\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        my_list = []\n",
    "        for n in range(46):\n",
    "            if rasters_csi_np_0[n][i][j] != 0:\n",
    "                my_list.append((n, rasters_csi_np_0[n][i][j]))\n",
    "        my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "        if len(my_list)>=3:\n",
    "            inds = [my_list[:3][k][0] for k in range(3)]\n",
    "            res = []\n",
    "            for m in inds:\n",
    "                if rasters_si_ind_np[m][i][j] == 1:\n",
    "                    res.append(m)\n",
    "            top3_crops_num[j][i] = res\n",
    "\n",
    "        \n",
    "# In top3_crops_num, 0 means that there are no TOP 3 crops in the cell\n",
    "# [a, c, b] means that crops by these ordinal numbers make the TOP 3 in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing indicators of representing TOP 3 crops in each cell \n",
    "\n",
    "top3_ind = np.zeros((46, 2160, 4320))\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if top3_crops_num[j][i] != 0:\n",
    "            if len(top3_crops_num[j][i])==3:\n",
    "                top3_ind[top3_crops_num[j][i][0]][i][j] = 1/3\n",
    "                top3_ind[top3_crops_num[j][i][1]][i][j] = 1/3 \n",
    "                top3_ind[top3_crops_num[j][i][2]][i][j] = 1/3 \n",
    "            elif len(top3_crops_num[j][i])==2:\n",
    "                top3_ind[top3_crops_num[j][i][0]][i][j] = 1/2\n",
    "                top3_ind[top3_crops_num[j][i][1]][i][j] = 1/2 \n",
    "            elif len(top3_crops_num[j][i])==1:\n",
    "                top3_ind[top3_crops_num[j][i][0]][i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "top3_crops_num_copy = top3_crops_num.copy()\n",
    "top3_crops_num_copy = (top3_crops_num_copy == 0)*1\n",
    "x = top3_crops_num_copy.astype('float64')\n",
    "x = x.to_numpy()\n",
    "\n",
    "for i in range(2160):\n",
    "    for j in range(4320):\n",
    "        if x[i][j]==1:\n",
    "            x[i][j]=np.nan\n",
    "        else: \n",
    "            x[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "cutoff_constraint_np = raster_to_numpy(Float(cutoff_constraint))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "for i in range(46):\n",
    "    top3_ind[i] = x * top3_ind[i] * cutoff_constraint_np\n",
    "\n",
    "# Saving indeces of representing TOP 3 crops in each cell \n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = numpy_to_raster(top3_ind[i])\n",
    "    out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_3\\\\csi_top3_ind\\\\' + rasters_csi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [26:25<00:00, 34.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "\n",
    "env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_3\\\\csi_top3_ind'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_3\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:20<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_3\\\\share'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_3\\\\share_squared\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A2a_3_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 19:19:50<br/>Succeeded at 5 июня 2023 г. 19:19:50 (Elapsed Time: 0,10 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A2a_3_READY.csv'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_3\\\\share_squared'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +\"\\\\A2\\\\top3crops\\\\A2_3\\\\RESULTS\", \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +\"\\\\A2\\\\top3crops\\\\A2_3\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A2a_3_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2a_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A2a_4(rasters_csi, rasters_si, continent):\n",
    "    \n",
    "    env.workspace = csi_path\n",
    "\n",
    "    rasters_csi_np_0 = []\n",
    "    for n in range(len(rasters_csi)):\n",
    "        rasters_csi_np_0.append(raster_to_numpy_0(rasters_csi[n]))\n",
    "\n",
    "    # Creating indicator-rasters for all crops which show whether SI in the specific cell is higher than 0.1 cutoff or not\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    rasters_si_ind_np = []\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        rasters_si_ind_np.append((raster_to_numpy(Float(rasters_si[i]))>=1000)*1)\n",
    "\n",
    "    # Finding out which crops make the TOP 3 in each cell\n",
    "\n",
    "    top3_crops_num = np.zeros((2160, 4320))\n",
    "    top3_crops_num = pd.DataFrame(top3_crops_num)\n",
    "    top3_crops_num = top3_crops_num.astype(object)\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            my_list = []\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if rasters_csi_np_0[n][i][j] != 0:\n",
    "                    my_list.append((n, rasters_csi_np_0[n][i][j]))\n",
    "            my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "            if len(my_list)>=3:\n",
    "                inds = [my_list[:3][k][0] for k in range(3)]\n",
    "                res = []\n",
    "                for m in inds:\n",
    "                    if rasters_si_ind_np[m][i][j] == 1:\n",
    "                        res.append(m)\n",
    "                top3_crops_num[j][i] = res\n",
    "\n",
    "    # Computing indicators of representing TOP 3 crops in each cell \n",
    "\n",
    "    top3_ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if top3_crops_num[j][i] != 0:\n",
    "                if len(top3_crops_num[j][i])==3:\n",
    "                    top3_ind[top3_crops_num[j][i][0]][i][j] = 1/3\n",
    "                    top3_ind[top3_crops_num[j][i][1]][i][j] = 1/3 \n",
    "                    top3_ind[top3_crops_num[j][i][2]][i][j] = 1/3 \n",
    "                elif len(top3_crops_num[j][i])==2:\n",
    "                    top3_ind[top3_crops_num[j][i][0]][i][j] = 1/2\n",
    "                    top3_ind[top3_crops_num[j][i][1]][i][j] = 1/2 \n",
    "                elif len(top3_crops_num[j][i])==1:\n",
    "                    top3_ind[top3_crops_num[j][i][0]][i][j] = 1\n",
    "\n",
    "    # Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "    top3_crops_num_copy = top3_crops_num.copy()\n",
    "    top3_crops_num_copy = (top3_crops_num_copy == 0)*1\n",
    "    x = top3_crops_num_copy.astype('float64')\n",
    "    x = x.to_numpy()\n",
    "\n",
    "    for i in range(2160):\n",
    "        for j in range(4320):\n",
    "            if x[i][j]==1:\n",
    "                x[i][j]=np.nan\n",
    "            else: \n",
    "                x[i][j]=1\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    # Defining maximum SI in each cell\n",
    "    max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "    # Avoiding cells where maximum SI <= 0.1\n",
    "    cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "    cutoff_constraint_np = raster_to_numpy(Float(cutoff_constraint))\n",
    "\n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    for i in range(len(rasters_csi)):\n",
    "        top3_ind[i] = x * top3_ind[i] * cutoff_constraint_np\n",
    "\n",
    "    # Saving indeces of representing TOP 3 crops in each cell \n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        out = numpy_to_raster(top3_ind[i])\n",
    "        out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\csi_top3_ind\\\\' + rasters_csi[i])\n",
    "\n",
    "    # Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\csi_top3_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A2a_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A2a_4(rasters_csi, rasters_si, continent):\n",
    "    # Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\csi_top3_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A2\\\\top3crops\\\\A2_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A2a_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [04:58<00:00, 27.17s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:03<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_4(rasters_csi=saf_rasters_csi, rasters_si = saf_rasters_si, continent='saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:05<00:00, 26.96s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_4(rasters_csi=naf_rasters_csi, rasters_si = naf_rasters_si, continent='naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:16<00:00, 27.28s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:18<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_4(rasters_csi=asia_rasters_csi, rasters_si = asia_rasters_si, continent='asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:53<00:00, 27.83s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:05<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_4(rasters_csi=eu_rasters_csi, rasters_si = eu_rasters_si, continent='eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:25<00:00, 27.56s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_4(rasters_csi=america_rasters_csi, rasters_si = america_rasters_si, continent='america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:24<00:00, 28.07s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.66it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2a_4(rasters_csi=oceania_rasters_csi, rasters_si = oceania_rasters_si, continent='oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_4_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_4_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_4_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_4_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_4_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2a_4_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A2a_4'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A2a_4']].to_excel(tables_path + '\\\\READY_country_level\\\\A2a_4_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A2b_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Finding out which crops make the TOP 5 in each cell\n",
    "\n",
    "top5_crops_num = np.zeros((2160, 4320))\n",
    "top5_crops_num = pd.DataFrame(top5_crops_num)\n",
    "top5_crops_num = top5_crops_num.astype(object)\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        my_list = []\n",
    "        for n in range(46):\n",
    "            if rasters_csi_np_0[n][i][j] != 0:\n",
    "                my_list.append((n, rasters_csi_np_0[n][i][j]))\n",
    "        my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "        if len(my_list)>=5:\n",
    "            top5_crops_num[j][i] = [my_list[:5][k][0] for k in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing indicators of representing TOP 5 crops in each cell \n",
    "\n",
    "top5_ind = np.zeros((46, 2160, 4320))\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if top5_crops_num[j][i] != 0:\n",
    "            top5_ind[top5_crops_num[j][i][0]][i][j] = 1/5\n",
    "            top5_ind[top5_crops_num[j][i][1]][i][j] = 1/5 \n",
    "            top5_ind[top5_crops_num[j][i][2]][i][j] = 1/5 \n",
    "            top5_ind[top5_crops_num[j][i][3]][i][j] = 1/5 \n",
    "            top5_ind[top5_crops_num[j][i][4]][i][j] = 1/5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "top5_crops_num_copy = top5_crops_num.copy()\n",
    "top5_crops_num_copy = (top5_crops_num_copy == 0)*1\n",
    "x = top5_crops_num_copy.astype('float64')\n",
    "x = x.to_numpy()\n",
    "\n",
    "for i in range(2160):\n",
    "    for j in range(4320):\n",
    "        if x[i][j]==1:\n",
    "            x[i][j]=np.nan\n",
    "        else: \n",
    "            x[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "for i in range(46):\n",
    "    top5_ind[i] = x * top5_ind[i]\n",
    "\n",
    "# Saving indeces of representing TOP 5 crops in each cell \n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = numpy_to_raster(top5_ind[i])\n",
    "    out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_1\\\\csi_top5_ind\\\\' + rasters_csi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [26:19<00:00, 34.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the share of cells for which crop c is in TOP 5 across regions (for all crops)\n",
    "# Takes 30 min to compute\n",
    "\n",
    "env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_1\\\\csi_top5_ind'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_1\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:20<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_1\\\\share'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_1\\\\share_squared\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A2b_1_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 20:09:05<br/>Succeeded at 5 июня 2023 г. 20:09:05 (Elapsed Time: 0,09 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A2b_1_READY.csv'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_1\\\\share_squared'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +\"\\\\A2\\\\top5crops\\\\A2_1\\\\RESULTS\", \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +\"\\\\A2\\\\top5crops\\\\A2_1\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A2b_1_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A2b_2(rasters_csi, continent):\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    rasters_csi_np_0 = []\n",
    "    for n in range(len(rasters_csi)):\n",
    "        rasters_csi_np_0.append(raster_to_numpy_0(rasters_csi[n]))\n",
    "\n",
    "    # Finding out which crops make the TOP 5 in each cell\n",
    "\n",
    "    top5_crops_num = np.zeros((2160, 4320))\n",
    "    top5_crops_num = pd.DataFrame(top5_crops_num)\n",
    "    top5_crops_num = top5_crops_num.astype(object)\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            my_list = []\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if rasters_csi_np_0[n][i][j] != 0:\n",
    "                    my_list.append((n, rasters_csi_np_0[n][i][j]))\n",
    "            my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "            if len(my_list)>=5:\n",
    "                top5_crops_num[j][i] = [my_list[:5][k][0] for k in range(5)]\n",
    "\n",
    "    # Computing indicators of representing TOP 5 crops in each cell \n",
    "\n",
    "    top5_ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if top5_crops_num[j][i] != 0:\n",
    "                top5_ind[top5_crops_num[j][i][0]][i][j] = 1/5\n",
    "                top5_ind[top5_crops_num[j][i][1]][i][j] = 1/5 \n",
    "                top5_ind[top5_crops_num[j][i][2]][i][j] = 1/5 \n",
    "                top5_ind[top5_crops_num[j][i][3]][i][j] = 1/5 \n",
    "                top5_ind[top5_crops_num[j][i][4]][i][j] = 1/5 \n",
    "\n",
    "\n",
    "    # Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "    top5_crops_num_copy = top5_crops_num.copy()\n",
    "    top5_crops_num_copy = (top5_crops_num_copy == 0)*1\n",
    "    x = top5_crops_num_copy.astype('float64')\n",
    "    x = x.to_numpy()\n",
    "\n",
    "    for i in range(2160):\n",
    "        for j in range(4320):\n",
    "            if x[i][j]==1:\n",
    "                x[i][j]=np.nan\n",
    "            else: \n",
    "                x[i][j]=1\n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    for i in range(len(rasters_csi)):\n",
    "        top5_ind[i] = x * top5_ind[i]\n",
    "\n",
    "    # Saving indeces of representing TOP 5 crops in each cell \n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        out = numpy_to_raster(top5_ind[i])\n",
    "        out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\csi_top5_ind\\\\' + rasters_csi[i])\n",
    "\n",
    "    # Calculating the share of cells for which crop c is in TOP 5 across regions (for all crops)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\csi_top5_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\'+ continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\'+ continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\share_squared'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A2b_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A2b_2(rasters_csi, continent):\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\csi_top5_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\'+ continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\'+ continent + '\\\\share'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\share_squared'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A2\\\\top5crops\\\\A2_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A2b_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:22<00:00, 29.30s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_2(rasters_csi=saf_rasters_csi, continent='saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:47<00:00, 29.30s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:07<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_2(rasters_csi=naf_rasters_csi, continent='naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:31<00:00, 27.85s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:09<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_2(rasters_csi=asia_rasters_csi, continent='asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:49<00:00, 27.60s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:05<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_2(rasters_csi=eu_rasters_csi, continent='eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:36<00:00, 28.30s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_2(rasters_csi=america_rasters_csi, continent='america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:27<00:00, 29.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_2(rasters_csi=oceania_rasters_csi, continent='oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_2_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_2_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_2_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_2_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_2_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_2_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A2b_2'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A2b_2']].to_excel(tables_path + '\\\\READY_country_level\\\\A2b_2_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A2b_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Finding out which crops make the TOP 5 in each cell\n",
    "\n",
    "top5_crops_num = np.zeros((2160, 4320))\n",
    "top5_crops_num = pd.DataFrame(top5_crops_num)\n",
    "top5_crops_num = top5_crops_num.astype(object)\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        my_list = []\n",
    "        for n in range(46):\n",
    "            if rasters_csi_np_0[n][i][j] != 0:\n",
    "                my_list.append((n, rasters_csi_np_0[n][i][j]))\n",
    "        my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "        if len(my_list)>=5:\n",
    "            inds = [my_list[:5][k][0] for k in range(5)]\n",
    "            res = []\n",
    "            for m in inds:\n",
    "                if rasters_si_ind_np[m][i][j] == 1:\n",
    "                    res.append(m)\n",
    "            top5_crops_num[j][i] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing indicators of representing TOP 5 crops in each cell \n",
    "\n",
    "top5_ind = np.zeros((46, 2160, 4320))\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if top5_crops_num[j][i] != 0:\n",
    "            if len(top5_crops_num[j][i])==5:\n",
    "                top5_ind[top5_crops_num[j][i][0]][i][j] = 1/5\n",
    "                top5_ind[top5_crops_num[j][i][1]][i][j] = 1/5 \n",
    "                top5_ind[top5_crops_num[j][i][2]][i][j] = 1/5\n",
    "                top5_ind[top5_crops_num[j][i][3]][i][j] = 1/5 \n",
    "                top5_ind[top5_crops_num[j][i][4]][i][j] = 1/5 \n",
    "            elif len(top5_crops_num[j][i])==4:\n",
    "                top5_ind[top5_crops_num[j][i][0]][i][j] = 1/4\n",
    "                top5_ind[top5_crops_num[j][i][1]][i][j] = 1/4 \n",
    "                top5_ind[top5_crops_num[j][i][2]][i][j] = 1/4\n",
    "                top5_ind[top5_crops_num[j][i][3]][i][j] = 1/4 \n",
    "            elif len(top5_crops_num[j][i])==3:\n",
    "                top5_ind[top5_crops_num[j][i][0]][i][j] = 1/3\n",
    "                top5_ind[top5_crops_num[j][i][1]][i][j] = 1/3 \n",
    "                top5_ind[top5_crops_num[j][i][2]][i][j] = 1/3 \n",
    "            elif len(top5_crops_num[j][i])==2:\n",
    "                top5_ind[top5_crops_num[j][i][0]][i][j] = 1/2\n",
    "                top5_ind[top5_crops_num[j][i][1]][i][j] = 1/2 \n",
    "            elif len(top5_crops_num[j][i])==1:\n",
    "                top5_ind[top5_crops_num[j][i][0]][i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "top5_crops_num_copy = top5_crops_num.copy()\n",
    "top5_crops_num_copy = (top5_crops_num_copy == 0)*1\n",
    "x = top5_crops_num_copy.astype('float64')\n",
    "x = x.to_numpy()\n",
    "\n",
    "for i in range(2160):\n",
    "    for j in range(4320):\n",
    "        if x[i][j]==1:\n",
    "            x[i][j]=np.nan\n",
    "        else: \n",
    "            x[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "cutoff_constraint_np = raster_to_numpy(Float(cutoff_constraint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "for i in range(46):\n",
    "    top5_ind[i] = x * top5_ind[i] * cutoff_constraint_np\n",
    "\n",
    "# Saving indeces of representing TOP 5 crops in each cell \n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = numpy_to_raster(top5_ind[i])\n",
    "    out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_3\\\\csi_top5_ind\\\\' + rasters_csi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [26:16<00:00, 34.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "\n",
    "env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_3\\\\csi_top5_ind'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_3\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:29<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_3\\\\share'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_3\\\\share_squared\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A2b_3_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 20:36:39<br/>Succeeded at 5 июня 2023 г. 20:36:39 (Elapsed Time: 0,09 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A2b_3_READY.csv'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_3\\\\share_squared'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +\"\\\\A2\\\\top5crops\\\\A2_3\\\\RESULTS\", \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +\"\\\\A2\\\\top5crops\\\\A2_3\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A2b_3_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2b_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A2b_4(rasters_csi, rasters_si, continent):\n",
    "    \n",
    "    env.workspace = csi_path\n",
    "\n",
    "    rasters_csi_np_0 = []\n",
    "    for n in range(len(rasters_csi)):\n",
    "        rasters_csi_np_0.append(raster_to_numpy_0(rasters_csi[n]))\n",
    "\n",
    "    # Creating indicator-rasters for all crops which show whether SI in the specific cell is higher than 0.1 cutoff or not\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    rasters_si_ind_np = []\n",
    "    for i in tqdm(range(len(rasters_si))):\n",
    "        rasters_si_ind_np.append((raster_to_numpy(Float(rasters_si[i]))>=1000)*1)\n",
    "\n",
    "    # Finding out which crops make the TOP 5 in each cell\n",
    "\n",
    "    top5_crops_num = np.zeros((2160, 4320))\n",
    "    top5_crops_num = pd.DataFrame(top5_crops_num)\n",
    "    top5_crops_num = top5_crops_num.astype(object)\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            my_list = []\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if rasters_csi_np_0[n][i][j] != 0:\n",
    "                    my_list.append((n, rasters_csi_np_0[n][i][j]))\n",
    "            my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "            if len(my_list)>=5:\n",
    "                inds = [my_list[:5][k][0] for k in range(5)]\n",
    "                res = []\n",
    "                for m in inds:\n",
    "                    if rasters_si_ind_np[m][i][j] == 1:\n",
    "                        res.append(m)\n",
    "                top5_crops_num[j][i] = res\n",
    "\n",
    "    # Computing indicators of representing TOP 5 crops in each cell \n",
    "\n",
    "    top5_ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if top5_crops_num[j][i] != 0:\n",
    "                if len(top5_crops_num[j][i])==5:\n",
    "                    top5_ind[top5_crops_num[j][i][0]][i][j] = 1/5\n",
    "                    top5_ind[top5_crops_num[j][i][1]][i][j] = 1/5 \n",
    "                    top5_ind[top5_crops_num[j][i][2]][i][j] = 1/5\n",
    "                    top5_ind[top5_crops_num[j][i][3]][i][j] = 1/5 \n",
    "                    top5_ind[top5_crops_num[j][i][4]][i][j] = 1/5 \n",
    "                elif len(top5_crops_num[j][i])==4:\n",
    "                    top5_ind[top5_crops_num[j][i][0]][i][j] = 1/4\n",
    "                    top5_ind[top5_crops_num[j][i][1]][i][j] = 1/4 \n",
    "                    top5_ind[top5_crops_num[j][i][2]][i][j] = 1/4\n",
    "                    top5_ind[top5_crops_num[j][i][3]][i][j] = 1/4 \n",
    "                elif len(top5_crops_num[j][i])==3:\n",
    "                    top5_ind[top5_crops_num[j][i][0]][i][j] = 1/3\n",
    "                    top5_ind[top5_crops_num[j][i][1]][i][j] = 1/3 \n",
    "                    top5_ind[top5_crops_num[j][i][2]][i][j] = 1/3 \n",
    "                elif len(top5_crops_num[j][i])==2:\n",
    "                    top5_ind[top5_crops_num[j][i][0]][i][j] = 1/2\n",
    "                    top5_ind[top5_crops_num[j][i][1]][i][j] = 1/2 \n",
    "                elif len(top5_crops_num[j][i])==1:\n",
    "                    top5_ind[top5_crops_num[j][i][0]][i][j] = 1\n",
    "\n",
    "    # Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "    top5_crops_num_copy = top5_crops_num.copy()\n",
    "    top5_crops_num_copy = (top5_crops_num_copy == 0)*1\n",
    "    x = top5_crops_num_copy.astype('float64')\n",
    "    x = x.to_numpy()\n",
    "\n",
    "    for i in range(2160):\n",
    "        for j in range(4320):\n",
    "            if x[i][j]==1:\n",
    "                x[i][j]=np.nan\n",
    "            else: \n",
    "                x[i][j]=1\n",
    "\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    # Defining maximum SI in each cell\n",
    "    max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "    # Avoiding cells where maximum SI <= 0.1\n",
    "    cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "    cutoff_constraint_np = raster_to_numpy(Float(cutoff_constraint))\n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    for i in range(len(rasters_csi)):\n",
    "        top5_ind[i] = x * top5_ind[i] * cutoff_constraint_np\n",
    "\n",
    "    # Saving indeces of representing TOP 5 crops in each cell \n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        out = numpy_to_raster(top5_ind[i])\n",
    "        out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\'+continent+'\\\\csi_top5_ind\\\\' + rasters_csi[i])\n",
    "\n",
    "\n",
    "    # Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\'+continent+'\\\\csi_top5_ind'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\share_squared'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A2b_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A2b_4(rasters_csi, rasters_si, continent):\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\'+continent+'\\\\csi_top5_ind'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\share_squared'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A2\\\\top5crops\\\\A2_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A2b_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:16<00:00, 28.73s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_4(rasters_csi=saf_rasters_csi, rasters_si = saf_rasters_si, continent='saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:50<00:00, 29.45s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:09<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_4(rasters_csi=naf_rasters_csi, rasters_si = naf_rasters_si, continent='naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:48<00:00, 28.47s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:09<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_4(rasters_csi=asia_rasters_csi, rasters_si = asia_rasters_si, continent='asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:38<00:00, 26.97s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:05<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_4(rasters_csi=eu_rasters_csi, rasters_si = eu_rasters_si, continent='eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:16<00:00, 26.93s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_4(rasters_csi=america_rasters_csi, rasters_si = america_rasters_si, continent='america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:22<00:00, 27.52s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.55it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A2b_4(rasters_csi=oceania_rasters_csi, rasters_si = oceania_rasters_si, continent='oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_4_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_4_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_4_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_4_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_4_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A2b_4_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A2b_4'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A2b_4']].to_excel(tables_path + '\\\\READY_country_level\\\\A2b_4_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Finding out which crops make the TOP 5 in each cell\n",
    "\n",
    "top5_crops_num = np.zeros((2160, 4320))\n",
    "top5_crops_num = pd.DataFrame(top5_crops_num)\n",
    "top5_crops_num = top5_crops_num.astype(object)\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        my_list = []\n",
    "        for n in range(46):\n",
    "            if rasters_csi_np_0[n][i][j] != 0:\n",
    "                my_list.append([n, rasters_csi_np_0[n][i][j]])\n",
    "        my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "        if len(my_list)>=5:\n",
    "            top5_crops_num[j][i] = [(my_list[:5][k][0], my_list[:5][k][1]) for k in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing indicators of representing TOP 5 crops in each cell \n",
    "\n",
    "top5_ind = np.zeros((46, 2160, 4320))\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if top5_crops_num[j][i] != 0:\n",
    "            sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] + top5_crops_num[j][i][2][1] + top5_crops_num[j][i][3][1] + top5_crops_num[j][i][4][1]\n",
    "            top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "            top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "            top5_ind[top5_crops_num[j][i][2][0]][i][j] = top5_crops_num[j][i][2][1]/sum_top5_csi\n",
    "            top5_ind[top5_crops_num[j][i][3][0]][i][j] = top5_crops_num[j][i][3][1]/sum_top5_csi\n",
    "            top5_ind[top5_crops_num[j][i][4][0]][i][j] = top5_crops_num[j][i][4][1]/sum_top5_csi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "top5_crops_num_copy = top5_crops_num.copy()\n",
    "top5_crops_num_copy = (top5_crops_num_copy == 0)*1\n",
    "x = top5_crops_num_copy.astype('float64')\n",
    "x = x.to_numpy()\n",
    "\n",
    "for i in range(2160):\n",
    "    for j in range(4320):\n",
    "        if x[i][j]==1:\n",
    "            x[i][j]=np.nan\n",
    "        else: \n",
    "            x[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "for i in range(46):\n",
    "    top5_ind[i] = x * top5_ind[i]\n",
    "\n",
    "# Saving indeces of representing TOP 5 crops in each cell \n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = numpy_to_raster(top5_ind[i])\n",
    "    out.save(tables_path + '\\\\A3\\\\A3_1\\\\csi_top5_ind\\\\' + rasters_csi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [26:10<00:00, 34.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the share of cells for which crop c is in TOP 5 across regions (for all crops)\n",
    "\n",
    "env.workspace = tables_path + '\\\\A3\\\\A3_1\\\\csi_top5_ind'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A3\\\\A3_1\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:19<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A3\\\\A3_1\\\\share'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A3\\\\A3_1\\\\share_squared\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A3_1_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 21:04:21<br/>Succeeded at 5 июня 2023 г. 21:04:21 (Elapsed Time: 0,09 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A3_1_READY.csv'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A3\\\\A3_1\\\\share_squared'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +\"\\\\A3\\\\A3_1\\\\RESULTS\", \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +\"\\\\A3\\\\A3_1\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A3_1_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A3_2(rasters_csi, continent):\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    rasters_csi_np_0 = []\n",
    "    for n in range(len(rasters_csi)):\n",
    "        rasters_csi_np_0.append(raster_to_numpy_0(rasters_csi[n]))\n",
    "\n",
    "    # Finding out which crops make the TOP 5 in each cell\n",
    "\n",
    "    top5_crops_num = np.zeros((2160, 4320))\n",
    "    top5_crops_num = pd.DataFrame(top5_crops_num)\n",
    "    top5_crops_num = top5_crops_num.astype(object)\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            my_list = []\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if rasters_csi_np_0[n][i][j] != 0:\n",
    "                    my_list.append([n, rasters_csi_np_0[n][i][j]])\n",
    "            my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "            if len(my_list)>=5:\n",
    "                top5_crops_num[j][i] = [(my_list[:5][k][0], my_list[:5][k][1]) for k in range(5)]\n",
    "\n",
    "    # Computing indicators of representing TOP 5 crops in each cell \n",
    "\n",
    "    top5_ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if top5_crops_num[j][i] != 0:\n",
    "                sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] + top5_crops_num[j][i][2][1] + top5_crops_num[j][i][3][1] + top5_crops_num[j][i][4][1]\n",
    "                top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "                top5_ind[top5_crops_num[j][i][2][0]][i][j] = top5_crops_num[j][i][2][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][3][0]][i][j] = top5_crops_num[j][i][3][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][4][0]][i][j] = top5_crops_num[j][i][4][1]/sum_top5_csi\n",
    "\n",
    "    # Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "    top5_crops_num_copy = top5_crops_num.copy()\n",
    "    top5_crops_num_copy = (top5_crops_num_copy == 0)*1\n",
    "    x = top5_crops_num_copy.astype('float64')\n",
    "    x = x.to_numpy()\n",
    "\n",
    "    for i in range(2160):\n",
    "        for j in range(4320):\n",
    "            if x[i][j]==1:\n",
    "                x[i][j]=np.nan\n",
    "            else: \n",
    "                x[i][j]=1\n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    for i in range(len(rasters_csi)):\n",
    "        top5_ind[i] = x * top5_ind[i]\n",
    "\n",
    "    # Saving indeces of representing TOP 5 crops in each cell \n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        out = numpy_to_raster(top5_ind[i])\n",
    "        out.save(tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\csi_top5_ind\\\\' + rasters_csi[i])\n",
    "\n",
    "    # Calculating the share of cells for which crop c is in TOP 5 across regions (for all crops)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\csi_top5_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A3\\\\A3_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A3\\\\A3_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A3_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A3_2(rasters_csi, continent):\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\csi_top5_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_2\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A3\\\\A3_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A3\\\\A3_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A3_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [04:59<00:00, 27.21s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:03<00:00,  3.10it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_2(rasters_csi = saf_rasters_csi, continent = 'saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:04<00:00, 26.91s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_2(rasters_csi = naf_rasters_csi, continent = 'naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:40<00:00, 27.08s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:07<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_2(rasters_csi = eu_rasters_csi, continent = 'eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:12<00:00, 27.12s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:09<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_2(rasters_csi = asia_rasters_csi, continent = 'asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:21<00:00, 27.06s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_2(rasters_csi = oceania_rasters_csi, continent = 'oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:21<00:00, 27.28s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:04<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_2(rasters_csi = america_rasters_csi, continent = 'america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_2_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_2_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_2_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_2_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_2_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_2_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A3_2'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A3_2']].to_excel(tables_path + '\\\\READY_country_level\\\\A3_2_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Finding out which crops make the TOP 5 in each cell\n",
    "\n",
    "top5_crops_num = np.zeros((2160, 4320))\n",
    "top5_crops_num = pd.DataFrame(top5_crops_num)\n",
    "top5_crops_num = top5_crops_num.astype(object)\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        my_list = []\n",
    "        for n in range(46):\n",
    "            if rasters_csi_np_0[n][i][j] != 0:\n",
    "                my_list.append([n, rasters_csi_np_0[n][i][j]])\n",
    "        my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "        if len(my_list)>=5:\n",
    "            inds = [(my_list[:5][k][0], my_list[:5][k][1]) for k in range(5)]\n",
    "            res = []\n",
    "            for m in inds:\n",
    "                if rasters_si_ind_np[m[0]][i][j] == 1:\n",
    "                    res.append(m)\n",
    "            top5_crops_num[j][i] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing indicators of representing TOP 5 crops in each cell \n",
    "\n",
    "top5_ind = np.zeros((46, 2160, 4320))\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if top5_crops_num[j][i] != 0:\n",
    "            if len(top5_crops_num[j][i])==5:\n",
    "                sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] + top5_crops_num[j][i][2][1] + top5_crops_num[j][i][3][1] + top5_crops_num[j][i][4][1]\n",
    "                top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "                top5_ind[top5_crops_num[j][i][2][0]][i][j] = top5_crops_num[j][i][2][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][3][0]][i][j] = top5_crops_num[j][i][3][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][4][0]][i][j] = top5_crops_num[j][i][4][1]/sum_top5_csi\n",
    "            elif len(top5_crops_num[j][i])==4:\n",
    "                sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] + top5_crops_num[j][i][2][1] + top5_crops_num[j][i][3][1] \n",
    "                top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "                top5_ind[top5_crops_num[j][i][2][0]][i][j] = top5_crops_num[j][i][2][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][3][0]][i][j] = top5_crops_num[j][i][3][1]/sum_top5_csi\n",
    "            elif len(top5_crops_num[j][i])==3:\n",
    "                sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] + top5_crops_num[j][i][2][1] \n",
    "                top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "                top5_ind[top5_crops_num[j][i][2][0]][i][j] = top5_crops_num[j][i][2][1]/sum_top5_csi\n",
    "            elif len(top5_crops_num[j][i])==2:\n",
    "                sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] \n",
    "                top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "            elif len(top5_crops_num[j][i])==1:\n",
    "                sum_top5_csi = top5_crops_num[j][i][0][1]\n",
    "                top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "top5_crops_num_copy = top5_crops_num.copy()\n",
    "top5_crops_num_copy = (top5_crops_num_copy == 0)*1\n",
    "x = top5_crops_num_copy.astype('float64')\n",
    "x = x.to_numpy()\n",
    "\n",
    "for i in range(2160):\n",
    "    for j in range(4320):\n",
    "        if x[i][j]==1:\n",
    "            x[i][j]=np.nan\n",
    "        else: \n",
    "            x[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "cutoff_constraint_np = raster_to_numpy(Float(cutoff_constraint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "for i in range(46):\n",
    "    top5_ind[i] = x * top5_ind[i] * cutoff_constraint_np\n",
    "\n",
    "# Saving indeces of representing TOP 5 crops in each cell \n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = numpy_to_raster(top5_ind[i])\n",
    "    out.save(tables_path + '\\\\A3\\\\A3_3\\\\csi_top5_ind\\\\' + rasters_csi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [25:59<00:00, 33.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "\n",
    "env.workspace = tables_path + '\\\\A3\\\\A3_3\\\\csi_top5_ind'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A3\\\\A3_3\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:19<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A3\\\\A3_3\\\\share\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A3\\\\A3_3\\\\share_squared\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A3_3_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 21:31:24<br/>Succeeded at 5 июня 2023 г. 21:31:25 (Elapsed Time: 0,10 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A3_3_READY.csv'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A3\\\\A3_3\\\\share_squared\\\\'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +\"\\\\A3\\\\A3_3\\\\RESULTS\", \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +\"\\\\A3\\\\A3_3\\\\RESULTS\", tables_path + '\\\\READY_country_level', 'A3_3_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A3_4(rasters_csi, rasters_si, continent):\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    rasters_csi_np_0 = []\n",
    "    for n in range(len(rasters_csi)):\n",
    "        rasters_csi_np_0.append(raster_to_numpy_0(rasters_csi[n]))\n",
    "\n",
    "    # Creating indicator-rasters for all crops which show whether SI in the specific cell is higher than 0.1 cutoff or not\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    rasters_si_ind_np = []\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        rasters_si_ind_np.append((raster_to_numpy(Float(rasters_si[i]))>=1000)*1)\n",
    "\n",
    "    # Finding out which crops make the TOP 5 in each cell\n",
    "\n",
    "    top5_crops_num = np.zeros((2160, 4320))\n",
    "    top5_crops_num = pd.DataFrame(top5_crops_num)\n",
    "    top5_crops_num = top5_crops_num.astype(object)\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            my_list = []\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if rasters_csi_np_0[n][i][j] != 0:\n",
    "                    my_list.append([n, rasters_csi_np_0[n][i][j]])\n",
    "            my_list = sorted(my_list, key = sort_key, reverse=True)\n",
    "            if len(my_list)>=5:\n",
    "                inds = [(my_list[:5][k][0], my_list[:5][k][1]) for k in range(5)]\n",
    "                res = []\n",
    "                for m in inds:\n",
    "                    if rasters_si_ind_np[m[0]][i][j] == 1:\n",
    "                        res.append(m)\n",
    "                top5_crops_num[j][i] = res\n",
    "\n",
    "    # Computing indicators of representing TOP 5 crops in each cell \n",
    "\n",
    "    top5_ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if top5_crops_num[j][i] != 0:\n",
    "                if len(top5_crops_num[j][i])==5:\n",
    "                    sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] + top5_crops_num[j][i][2][1] + top5_crops_num[j][i][3][1] + top5_crops_num[j][i][4][1]\n",
    "                    top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                    top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "                    top5_ind[top5_crops_num[j][i][2][0]][i][j] = top5_crops_num[j][i][2][1]/sum_top5_csi\n",
    "                    top5_ind[top5_crops_num[j][i][3][0]][i][j] = top5_crops_num[j][i][3][1]/sum_top5_csi\n",
    "                    top5_ind[top5_crops_num[j][i][4][0]][i][j] = top5_crops_num[j][i][4][1]/sum_top5_csi\n",
    "                elif len(top5_crops_num[j][i])==4:\n",
    "                    sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] + top5_crops_num[j][i][2][1] + top5_crops_num[j][i][3][1] \n",
    "                    top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                    top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "                    top5_ind[top5_crops_num[j][i][2][0]][i][j] = top5_crops_num[j][i][2][1]/sum_top5_csi\n",
    "                    top5_ind[top5_crops_num[j][i][3][0]][i][j] = top5_crops_num[j][i][3][1]/sum_top5_csi\n",
    "                elif len(top5_crops_num[j][i])==3:\n",
    "                    sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] + top5_crops_num[j][i][2][1] \n",
    "                    top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                    top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "                    top5_ind[top5_crops_num[j][i][2][0]][i][j] = top5_crops_num[j][i][2][1]/sum_top5_csi\n",
    "                elif len(top5_crops_num[j][i])==2:\n",
    "                    sum_top5_csi = top5_crops_num[j][i][0][1] + top5_crops_num[j][i][1][1] \n",
    "                    top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi\n",
    "                    top5_ind[top5_crops_num[j][i][1][0]][i][j] = top5_crops_num[j][i][1][1]/sum_top5_csi \n",
    "                elif len(top5_crops_num[j][i])==1:\n",
    "                    sum_top5_csi = top5_crops_num[j][i][0][1]\n",
    "                    top5_ind[top5_crops_num[j][i][0][0]][i][j] = top5_crops_num[j][i][0][1]/sum_top5_csi \n",
    "\n",
    "\n",
    "    # Creating the multiplicator to take into account 'No Data' and zero values in our indicators \n",
    "\n",
    "    top5_crops_num_copy = top5_crops_num.copy()\n",
    "    top5_crops_num_copy = (top5_crops_num_copy == 0)*1\n",
    "    x = top5_crops_num_copy.astype('float64')\n",
    "    x = x.to_numpy()\n",
    "\n",
    "    for i in range(2160):\n",
    "        for j in range(4320):\n",
    "            if x[i][j]==1:\n",
    "                x[i][j]=np.nan\n",
    "            else: \n",
    "                x[i][j]=1\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    # Defining maximum SI in each cell\n",
    "    max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "    # Avoiding cells where maximum SI <= 0.1\n",
    "    cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "    cutoff_constraint_np = raster_to_numpy(Float(cutoff_constraint))\n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    for i in range(len(rasters_csi)):\n",
    "        top5_ind[i] = x * top5_ind[i] * cutoff_constraint_np\n",
    "\n",
    "    # Saving indeces of representing TOP 5 crops in each cell \n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        out = numpy_to_raster(top5_ind[i])\n",
    "        out.save(tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\csi_top5_ind\\\\' + rasters_csi[i])\n",
    "\n",
    "    # Calculating the share of cells for which crop c is in TOP 3 across regions (for all crops)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\csi_top5_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A3\\\\A3_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A3\\\\A3_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A3_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A3_4(rasters_csi, rasters_si, continent):\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\csi_top5_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A3\\\\A3_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A3\\\\A3_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A3\\\\A3_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A3_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [04:59<00:00, 27.22s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:03<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_4(rasters_csi=saf_rasters_csi, rasters_si = saf_rasters_si, continent='saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:41<00:00, 28.98s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_4(rasters_csi=naf_rasters_csi, rasters_si = naf_rasters_si, continent='naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [13:22<00:00, 29.72s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:17<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_4(rasters_csi=asia_rasters_csi, rasters_si = asia_rasters_si, continent='asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:45<00:00, 27.36s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_4(rasters_csi=eu_rasters_csi, rasters_si = eu_rasters_si, continent='eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:30<00:00, 27.89s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_4(rasters_csi=america_rasters_csi, rasters_si = america_rasters_si, continent='america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:24<00:00, 28.10s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A3_4(rasters_csi=oceania_rasters_csi, rasters_si = oceania_rasters_si, continent='oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_4_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_4_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_4_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_4_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_4_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A3_4_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A3_4'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A3_4']].to_excel(tables_path + '\\\\READY_country_level\\\\A3_4_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = csi_path\n",
    "\n",
    "# Defining maximum CSI in each cell\n",
    "csi_mean_among_all_cells = Float(arcpy.sa.CellStatistics(rasters_csi, 'MEAN', 'DATA'))\n",
    "csi_mean_among_all_cells.save(tables_path + '\\\\A4\\\\A4_1\\\\csi_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for raster in rasters_csi:\n",
    "    out = Float(GreaterThan(raster, csi_mean_among_all_cells))\n",
    "    out.save(tables_path + '\\\\A4\\\\A4_1\\\\csi_mean_ind\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\A4\\\\A4_1\\\\csi_mean_ind\\\\'\n",
    "\n",
    "all_crops_np = []\n",
    "for i in range(46):\n",
    "    all_crops_np.append(raster_to_numpy(rasters_csi[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_ind = np.zeros((46, 2160, 4320))\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        my_list = []\n",
    "        for n in range(46):\n",
    "            if all_crops_np[n][i][j] == 1:\n",
    "                my_list.append([n, rasters_csi_np[n][i][j]])\n",
    "        sum_mean_csi = 0\n",
    "        for m in range(len(my_list)):       \n",
    "            sum_mean_csi += my_list[m][1] \n",
    "        for m in range(len(my_list)):\n",
    "            mean_ind[my_list[m][0]][i][j] = rasters_csi_np[my_list[m][0]][i][j]/sum_mean_csi        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "no_data_np = np.zeros((2160, 4320))\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if np.isnan(all_crops_np[0][i][j])==True:\n",
    "            no_data_np[i][j] = np.nan\n",
    "        else:\n",
    "            no_data_np[i][j] = 1\n",
    "\n",
    "# Saving indeces of representing Higher than MEAN crops in each cell\n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for n in range(46):\n",
    "    mean_ind[n] = mean_ind[n] * no_data_np\n",
    "    out = numpy_to_raster(mean_ind[n])\n",
    "    out.save(tables_path + '\\\\A4\\\\A4_1\\\\csi_mean_ind\\\\' + rasters_csi[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [25:56<00:00, 33.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "env.workspace = tables_path + '\\\\A4\\\\A4_1\\\\csi_mean_ind\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A4\\\\A4_1\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:27<00:00,  1.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A4_1_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 21:58:36<br/>Succeeded at 5 июня 2023 г. 21:58:36 (Elapsed Time: 0,09 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A4_1_READY.csv'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A4\\\\A4_1\\\\share\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A4\\\\A4_1\\\\share_squared\\\\' + raster)\n",
    "\n",
    "env.workspace = tables_path + '\\\\A4\\\\A4_1\\\\share_squared\\\\'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +'\\\\A4\\\\A4_1\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +'\\\\A4\\\\A4_1\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A4_1_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A4_2(rasters_csi, continent):\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    # Defining maximum CSI in each cell\n",
    "    csi_mean_among_all_cells = Float(arcpy.sa.CellStatistics(rasters_csi, 'MEAN', 'DATA'))\n",
    "\n",
    "    for raster in rasters_csi:\n",
    "        out = Float(GreaterThan(raster, csi_mean_among_all_cells))\n",
    "        out.save(tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\csi_mean_ind\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\csi_mean_ind\\\\'\n",
    "\n",
    "    all_crops_np = []\n",
    "    for i in range(len(rasters_csi)):\n",
    "        all_crops_np.append(raster_to_numpy(rasters_csi[i]))\n",
    "\n",
    "\n",
    "    mean_ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            my_list = []\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if all_crops_np[n][i][j] == 1:\n",
    "                    my_list.append([n, rasters_csi_np[n][i][j]])\n",
    "            sum_mean_csi = 0\n",
    "            for m in range(len(my_list)):       \n",
    "                sum_mean_csi += my_list[m][1]\n",
    "            if sum_mean_csi > 0:\n",
    "                for m in range(len(my_list)):\n",
    "                    mean_ind[my_list[m][0]][i][j] = rasters_csi_np[my_list[m][0]][i][j]/sum_mean_csi \n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    no_data_np = np.zeros((2160, 4320))\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if np.isnan(all_crops_np[0][i][j])==True:\n",
    "                no_data_np[i][j] = np.nan\n",
    "            else:\n",
    "                no_data_np[i][j] = 1\n",
    "\n",
    "    # Saving indeces of representing Higher than MEAN crops in each cell\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for n in range(len(rasters_csi)):\n",
    "        mean_ind[n] = mean_ind[n] * no_data_np\n",
    "        out = numpy_to_raster(mean_ind[n])\n",
    "        out.save(tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\csi_mean_ind\\\\' + rasters_csi[n])\n",
    "\n",
    "\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\csi_mean_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A4\\\\A4_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A4\\\\A4_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A4_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A4_2(rasters_csi, continent):\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\csi_mean_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_2\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A4\\\\A4_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A4\\\\A4_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A4_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:09<00:00, 28.12s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_2(rasters_csi = saf_rasters_csi, continent = 'saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:09<00:00, 27.21s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_2(rasters_csi = naf_rasters_csi, continent = 'naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:42<00:00, 27.21s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_2(rasters_csi = eu_rasters_csi, continent = 'eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:06<00:00, 26.89s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:09<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_2(rasters_csi = asia_rasters_csi, continent = 'asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:23<00:00, 27.67s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_2(rasters_csi = oceania_rasters_csi, continent = 'oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:16<00:00, 26.92s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_2(rasters_csi = america_rasters_csi, continent = 'america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_2_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_2_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_2_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_2_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_2_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_2_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A4_2'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A4_2']].to_excel(tables_path + '\\\\READY_country_level\\\\A4_2_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A4_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "\n",
    "# Creating CSI rasters which satisfy the constraint:\n",
    "# 1) max SI across all crops >= 0.1 (suitable cell for agriculture)\n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = Raster(csi_path + '\\\\' + rasters_csi[i]) * Raster(cutoff_constraint)\n",
    "    Float(out).save(tables_path + '\\\\A4\\\\A4_3\\\\rastersXind\\\\' + rasters_csi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\A4\\\\A4_3\\\\rastersXind\\\\'\n",
    "\n",
    "# Defining mean CSI in each cell\n",
    "csi_mean_among_all_cells = Float(arcpy.sa.CellStatistics(rasters_csi, 'MEAN', 'DATA'))\n",
    "csi_mean_among_all_cells.save(tables_path + '\\\\A4\\\\A4_3\\\\csi_mean')\n",
    "\n",
    "for raster in rasters_csi:\n",
    "    out = Float(GreaterThan(raster, csi_mean_among_all_cells))\n",
    "    out.save(tables_path + '\\\\A4\\\\A4_3\\\\csi_mean_ind\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\A4\\\\A4_3\\\\csi_mean_ind\\\\'\n",
    "\n",
    "all_crops_np = []\n",
    "for i in range(46):\n",
    "    all_crops_np.append(raster_to_numpy(rasters_csi[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_ind = np.zeros((46, 2160, 4320))\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        res = []\n",
    "        for n in range(46):\n",
    "            if all_crops_np[n][i][j] == 1:\n",
    "                res.append([n, rasters_csi_np[n][i][j]])\n",
    "        my_list = []\n",
    "        for m in res:\n",
    "             if rasters_si_ind_np[m[0]][i][j] == 1:\n",
    "                    my_list.append(m)\n",
    "                    \n",
    "        sum_mean_csi = 0\n",
    "        for m in range(len(my_list)):       \n",
    "            sum_mean_csi += my_list[m][1] \n",
    "        for m in range(len(my_list)):\n",
    "            mean_ind[my_list[m][0]][i][j] = rasters_csi_np[my_list[m][0]][i][j]/sum_mean_csi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "no_data_np = np.zeros((2160, 4320))\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if np.isnan(all_crops_np[0][i][j])==True:\n",
    "            no_data_np[i][j] = np.nan\n",
    "        else:\n",
    "            no_data_np[i][j] = 1\n",
    "\n",
    "# Saving indeces of representing Higher than MEAN crops in each cell\n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for n in range(46):\n",
    "    mean_ind[n] = mean_ind[n] * no_data_np\n",
    "    out = numpy_to_raster(mean_ind[n])\n",
    "    out.save(tables_path + '\\\\A4\\\\A4_3\\\\csi_mean_ind\\\\' + rasters_csi[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [26:22<00:00, 34.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "env.workspace = tables_path + '\\\\A4\\\\A4_3\\\\csi_mean_ind\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A4\\\\A4_3\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:18<00:00,  2.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A4_3_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 22:26:07<br/>Succeeded at 5 июня 2023 г. 22:26:07 (Elapsed Time: 0,11 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A4_3_READY.csv'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A4\\\\A4_3\\\\share\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A4\\\\A4_3\\\\share_squared\\\\' + raster)\n",
    "\n",
    "env.workspace = tables_path + '\\\\A4\\\\A4_3\\\\share_squared\\\\'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +'\\\\A4\\\\A4_3\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +'\\\\A4\\\\A4_3\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A4_3_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A4_4(rasters_csi, rasters_si, continent):\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_3\\\\rastersXind\\\\'\n",
    "\n",
    "    # Defining mean CSI in each cell\n",
    "    csi_mean_among_all_cells = Float(arcpy.sa.CellStatistics(rasters_csi, 'MEAN', 'DATA'))\n",
    "\n",
    "    for raster in rasters_csi:\n",
    "        out = Float(GreaterThan(raster, csi_mean_among_all_cells))\n",
    "        out.save(tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\csi_mean_ind\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\csi_mean_ind\\\\'\n",
    "\n",
    "    all_crops_np = []\n",
    "    for i in range(len(rasters_csi)):\n",
    "        all_crops_np.append(raster_to_numpy(rasters_csi[i]))  \n",
    "\n",
    "    # Creating indicator-rasters for all crops which show whether SI in the specific cell is higher than 0.1 cutoff or not\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    rasters_si_ind_np = []\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        rasters_si_ind_np.append((raster_to_numpy(Float(rasters_si[i]))>=1000)*1)\n",
    "\n",
    "\n",
    "    mean_ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            res = []\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if all_crops_np[n][i][j] == 1:\n",
    "                    res.append([n, rasters_csi_np[n][i][j]])\n",
    "            my_list = []\n",
    "            for m in res:\n",
    "                 if rasters_si_ind_np[m[0]][i][j] == 1:\n",
    "                        my_list.append(m)\n",
    "\n",
    "            sum_mean_csi = 0\n",
    "            for m in range(len(my_list)):       \n",
    "                sum_mean_csi += my_list[m][1] \n",
    "            if sum_mean_csi > 0:    \n",
    "                for m in range(len(my_list)):\n",
    "                    mean_ind[my_list[m][0]][i][j] = rasters_csi_np[my_list[m][0]][i][j]/sum_mean_csi     \n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    no_data_np = np.zeros((2160, 4320))\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if np.isnan(all_crops_np[0][i][j])==True:\n",
    "                no_data_np[i][j] = np.nan\n",
    "            else:\n",
    "                no_data_np[i][j] = 1\n",
    "\n",
    "    # Saving indeces of representing Higher than MEAN crops in each cell\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for n in range(len(rasters_csi)):\n",
    "        mean_ind[n] = mean_ind[n] * no_data_np\n",
    "        out = numpy_to_raster(mean_ind[n])\n",
    "        out.save(tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\csi_mean_ind\\\\' + rasters_csi[n])   \n",
    "\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\csi_mean_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A4\\\\A4_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A4\\\\A4_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A4_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A4_4(rasters_csi, rasters_si, continent):\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\csi_mean_ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A4\\\\A4_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A4\\\\A4_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A4\\\\A4_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A4_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [04:53<00:00, 26.69s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_4(rasters_csi=saf_rasters_csi, rasters_si = saf_rasters_si, continent='saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:04<00:00, 26.94s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_4(rasters_csi=naf_rasters_csi, rasters_si = naf_rasters_si, continent='naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:17<00:00, 27.31s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:09<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_4(rasters_csi=asia_rasters_csi, rasters_si = asia_rasters_si, continent='asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:44<00:00, 27.30s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_4(rasters_csi=eu_rasters_csi, rasters_si = eu_rasters_si, continent='eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:21<00:00, 27.24s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_4(rasters_csi=america_rasters_csi, rasters_si = america_rasters_si, continent='america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:22<00:00, 27.35s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A4_4(rasters_csi=oceania_rasters_csi, rasters_si = oceania_rasters_si, continent='oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_4_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_4_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_4_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_4_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_4_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A4_4_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A4_4'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A4_4']].to_excel(tables_path + '\\\\READY_country_level\\\\A4_4_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A5_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind = np.zeros((46, 2160, 4320))\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        sum_csi = 0\n",
    "        for n in range(46):\n",
    "            if rasters_csi_np[n][i][j]>=0:\n",
    "                sum_csi += rasters_csi_np[n][i][j]\n",
    "        if sum_csi > 0:\n",
    "            for n in range(46):\n",
    "                ind[n][i][j] = rasters_csi_np[n][i][j] / sum_csi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "no_data_np = np.zeros((2160, 4320))\n",
    "\n",
    "x = raster_to_numpy(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if np.isnan(x[i][j])==True:\n",
    "            no_data_np[i][j] = np.nan\n",
    "        else:\n",
    "            no_data_np[i][j] = 1\n",
    "\n",
    "# Saving indeces of representing Higher than MEAN crops in each cell\n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for n in range(46):\n",
    "    ind[n] = ind[n] * no_data_np\n",
    "    out = numpy_to_raster(ind[n])\n",
    "    out.save(tables_path + '\\\\A5\\\\A5_1\\\\ind\\\\' + rasters_csi[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [26:08<00:00, 34.09s/it]\n"
     ]
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A5\\\\A5_1\\\\ind\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A5\\\\A5_1\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:18<00:00,  2.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A5_1_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 22:58:32<br/>Succeeded at 5 июня 2023 г. 22:58:32 (Elapsed Time: 0,08 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A5_1_READY.csv'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A5\\\\A5_1\\\\share\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A5\\\\A5_1\\\\share_squared\\\\' + raster)\n",
    "\n",
    "env.workspace = tables_path + '\\\\A5\\\\A5_1\\\\share_squared\\\\'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +'\\\\A5\\\\A5_1\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +'\\\\A5\\\\A5_1\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A5_1_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A5_2 (rasters_csi, continent): \n",
    "\n",
    "    # Making np.arrays with CSI data for all crops\n",
    "    \n",
    "    env.workspace = csi_path\n",
    "\n",
    "    rasters_csi_np = []\n",
    "    for n in range(len(rasters_csi)):\n",
    "        rasters_csi_np.append(raster_to_numpy(rasters_csi[n]))\n",
    "\n",
    "    ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            sum_csi = 0\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if rasters_csi_np[n][i][j]>=0:\n",
    "                    sum_csi += rasters_csi_np[n][i][j]\n",
    "            if sum_csi > 0:\n",
    "                for n in range(len(rasters_csi)):\n",
    "                    ind[n][i][j] = rasters_csi_np[n][i][j] / sum_csi   \n",
    "\n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    no_data_np = np.zeros((2160, 4320))\n",
    "\n",
    "    x = raster_to_numpy(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if np.isnan(x[i][j])==True:\n",
    "                no_data_np[i][j] = np.nan\n",
    "            else:\n",
    "                no_data_np[i][j] = 1\n",
    "\n",
    "    # Saving indeces of representing Higher than MEAN crops in each cell\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for n in range(len(rasters_csi)):\n",
    "        ind[n] = ind[n] * no_data_np\n",
    "        out = numpy_to_raster(ind[n])\n",
    "        out.save(tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\ind\\\\' + rasters_csi[n])\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A5\\\\A5_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A5\\\\A5_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A5_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A5_2 (rasters_csi, continent):     \n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_2\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A5\\\\A5_2\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A5\\\\A5_2\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A5_2_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:03<00:00, 27.63s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_2(rasters_csi = saf_rasters_csi, continent = 'saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:14<00:00, 27.49s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_2(rasters_csi = naf_rasters_csi, continent = 'naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:48<00:00, 27.55s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_2(rasters_csi = eu_rasters_csi, continent = 'eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:16<00:00, 27.28s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:10<00:00,  2.68it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_2(rasters_csi = asia_rasters_csi, continent = 'asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:23<00:00, 27.81s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_2(rasters_csi = oceania_rasters_csi, continent = 'oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [09:35<00:00, 41.11s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_2(rasters_csi = america_rasters_csi, continent = 'america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_2_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_2_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_2_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_2_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_2_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_2_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A5_2'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A5_2']].to_excel(tables_path + '\\\\READY_country_level\\\\A5_2_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rasters_si_ind = []\n",
    "for i in range(46):\n",
    "    rasters_si_ind.append((rasters_si_np[i]>=1000)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind = np.zeros((46, 2160, 4320))\n",
    "\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        sum_csi = 0\n",
    "        for n in range(46):\n",
    "            if rasters_csi_np[n][i][j]>=0:\n",
    "                if rasters_si_ind[n][i][j]==1:\n",
    "                    sum_csi += rasters_csi_np[n][i][j]\n",
    "        if sum_csi > 0:\n",
    "            for n in range(46):\n",
    "                if rasters_si_ind[n][i][j]==1:\n",
    "                    ind[n][i][j] = rasters_csi_np[n][i][j] / sum_csi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding 'No data' values to our indicators \n",
    "\n",
    "no_data_np = np.zeros((2160, 4320))\n",
    "\n",
    "x = raster_to_numpy(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')\n",
    "for i in tqdm(range(2160)):\n",
    "    for j in range(4320):\n",
    "        if np.isnan(x[i][j])==True:\n",
    "            no_data_np[i][j] = np.nan\n",
    "        else:\n",
    "            no_data_np[i][j] = 1\n",
    "            \n",
    "            \n",
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "cutoff_constraint_np = raster_to_numpy(Float(cutoff_constraint))\n",
    "\n",
    "# Saving indeces of representing Higher than MEAN crops in each cell\n",
    "\n",
    "env.workspace = csi_path\n",
    "\n",
    "for n in range(46):\n",
    "    ind[n] = ind[n] * no_data_np * cutoff_constraint_np\n",
    "    out = numpy_to_raster(ind[n])\n",
    "    out.save(tables_path + '\\\\A5\\\\A5_3\\\\ind\\\\' + rasters_csi[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [27:45<00:00, 36.21s/it]\n"
     ]
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\A5\\\\A5_3\\\\ind\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "    out.save(tables_path + '\\\\A5\\\\A5_3\\\\share\\\\' + raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:19<00:00,  2.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\A5_3_READY.csv<h2>Messages</h2>Start Time: 5 июня 2023 г. 23:27:23<br/>Succeeded at 5 июня 2023 г. 23:27:24 (Elapsed Time: 0,12 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\A5_3_READY.csv'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final steps to compute ready indeces\n",
    "\n",
    "env.workspace = tables_path + '\\\\A5\\\\A5_3\\\\share\\\\'\n",
    "\n",
    "for raster in tqdm(rasters_csi):\n",
    "    #calculating squares \n",
    "    sq = Square(raster)\n",
    "    sq.save(tables_path + '\\\\A5\\\\A5_3\\\\share_squared\\\\' + raster)\n",
    "\n",
    "env.workspace = tables_path + '\\\\A5\\\\A5_3\\\\share_squared\\\\'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +'\\\\A5\\\\A5_3\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +'\\\\A5\\\\A5_3\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A5_3_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A5_4(rasters_csi, rasters_si, continent):\n",
    "\n",
    "    # Creating indicator-rasters for all crops which show whether SI in the specific cell is higher than 0.1 cutoff or not\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    rasters_si_ind = []\n",
    "    for i in tqdm(range(len(rasters_csi))):\n",
    "        rasters_si_ind.append((raster_to_numpy(Float(rasters_si[i]))>=1000)*1)\n",
    "\n",
    "    ind = np.zeros((len(rasters_csi), 2160, 4320))\n",
    "\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            sum_csi = 0\n",
    "            for n in range(len(rasters_csi)):\n",
    "                if rasters_csi_np[n][i][j]>=0:\n",
    "                    if rasters_si_ind[n][i][j]==1:\n",
    "                        sum_csi += rasters_csi_np[n][i][j]\n",
    "            if sum_csi > 0:\n",
    "                for n in range(len(rasters_csi)):\n",
    "                    if rasters_si_ind[n][i][j]==1:\n",
    "                        ind[n][i][j] = rasters_csi_np[n][i][j] / sum_csi\n",
    "\n",
    "\n",
    "    # Adding 'No data' values to our indicators \n",
    "\n",
    "    no_data_np = np.zeros((2160, 4320))\n",
    "\n",
    "    x = raster_to_numpy(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')\n",
    "    for i in tqdm(range(2160)):\n",
    "        for j in range(4320):\n",
    "            if np.isnan(x[i][j])==True:\n",
    "                no_data_np[i][j] = np.nan\n",
    "            else:\n",
    "                no_data_np[i][j] = 1\n",
    "\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "\n",
    "    # Defining maximum SI in each cell\n",
    "    max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "\n",
    "    # Avoiding cells where maximum SI <= 0.1\n",
    "    cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "    cutoff_constraint_np = raster_to_numpy(Float(cutoff_constraint))\n",
    "\n",
    "    # Saving indeces of representing Higher than MEAN crops in each cell\n",
    "\n",
    "    env.workspace = csi_path\n",
    "\n",
    "    for n in range(len(rasters_csi)):\n",
    "        ind[n] = ind[n] * no_data_np * cutoff_constraint_np\n",
    "        out = numpy_to_raster(ind[n])\n",
    "        out.save(tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\ind\\\\' + rasters_csi[n])\n",
    "\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A5\\\\A5_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A5\\\\A5_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY', 'A5_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_A5_4(rasters_csi, rasters_si, continent):\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\ind\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        out = ZonalStatistics(regions_shape_path, VAR, raster, \"MEAN\", \"DATA\")\n",
    "        out.save(tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\share\\\\' + raster)\n",
    "\n",
    "\n",
    "    # Final steps to compute ready indeces\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\share\\\\'\n",
    "\n",
    "    for raster in tqdm(rasters_csi):\n",
    "        #calculating squares \n",
    "        sq = Square(raster)\n",
    "        sq.save(tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\share_squared\\\\' + raster)\n",
    "\n",
    "    env.workspace = tables_path + '\\\\A5\\\\A5_4\\\\' + continent + '\\\\share_squared\\\\'\n",
    "\n",
    "    out = Float(arcpy.sa.CellStatistics(rasters_csi, 'SUM', 'DATA'))\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                            tables_path +'\\\\A5\\\\A5_4\\\\' + continent + '\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "    tt(tables_path +'\\\\A5\\\\A5_4\\\\' + continent + '\\\\RESULTS', tables_path + '\\\\READY_country_level', 'A5_4_' + continent + '_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:02<00:00, 27.53s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:03<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_4(rasters_csi=saf_rasters_csi, rasters_si = saf_rasters_si, continent='saf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [08:08<00:00, 27.14s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_4(rasters_csi=naf_rasters_csi, rasters_si = naf_rasters_si, continent='naf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [12:27<00:00, 27.69s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:09<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_4(rasters_csi=asia_rasters_csi, rasters_si = asia_rasters_si, continent='asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:50<00:00, 27.65s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:05<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_4(rasters_csi=eu_rasters_csi, rasters_si = eu_rasters_si, continent='eu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:36<00:00, 28.31s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.68it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_4(rasters_csi=america_rasters_csi, rasters_si = america_rasters_si, continent='america')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:24<00:00, 28.04s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "computing_A5_4(rasters_csi=oceania_rasters_csi, rasters_si = oceania_rasters_si, continent='oceania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_4_eu_READY.csv', sep = ';', decimal=',')\n",
    "saf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_4_saf_READY.csv', sep = ';', decimal=',')\n",
    "naf = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_4_naf_READY.csv', sep = ';', decimal=',')\n",
    "oceania = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_4_oceania_READY.csv', sep = ';', decimal=',')\n",
    "asia = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_4_asia_READY.csv', sep = ';', decimal=',')\n",
    "america = pd.read_csv(tables_path + '\\\\READY_country_level\\\\A5_4_america_READY.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [eu, saf, naf, oceania, asia, america]\n",
    "lst_n = ['eu', 'saf', 'naf', 'oceania', 'asia', 'america']\n",
    "for i in range(len(lst)): \n",
    "    lst[i].rename(columns = {\"MAX\": lst_n[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = asia.merge(eu[[VAR, 'eu']], how= 'left', on = VAR).merge(america[[VAR, 'america']], how= 'left', on = VAR).merge(saf[[VAR, 'saf']], how= 'left', on = VAR).merge(naf[[VAR, 'naf']], how= 'left', on = VAR).merge(oceania[[VAR, 'oceania']], how= 'left', on = VAR)\n",
    "res.fillna(0, inplace=True)\n",
    "res = res.merge(regions_pre1500, on=VAR, how='left').drop(['rcode', 'REGIONID'], axis=1).drop_duplicates().reset_index(drop=True)\n",
    "res['A5_4'] = res['Subsaharan Africa'] * res['saf'] + res['North Africa'] * res['naf'] + res['Europe'] * res['eu'] + res['Asia'] * res['asia'] + res['Oceania'] * res['oceania'] + res['America'] * res['america']  \n",
    "res[[VAR, 'COUNT', 'AREA', 'A5_4']].to_excel(tables_path + '\\\\READY_country_level\\\\A5_4_READY.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## B0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\B0\\help_tables\\B0_1_ready.csv<h2>Messages</h2>Start Time: 6 июня 2023 г. 0:12:16<br/>Succeeded at 6 июня 2023 г. 0:12:17 (Elapsed Time: 0,12 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\B0\\\\help_tables\\\\B0_1_ready.csv'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = dtb_path\n",
    "\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[0],\n",
    "                        tables_path +'\\\\B0\\\\B0_1\\\\RESULTS', \"DATA\", \"STD\")\n",
    "tt(tables_path +'\\\\B0\\\\B0_1\\\\RESULTS', tables_path + '\\\\B0\\\\help_tables', 'B0_1_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [48:39<00:00, 64.87s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(tables_path + \"\\\\B0\\\\help_tables\\\\B0_1_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"STD\"]/10000\n",
    "\n",
    "for i in tqdm(range(1, 46)):\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[i],\n",
    "                        tables_path +'\\\\B0\\\\B0_1\\\\RESULTS', \"DATA\", \"STD\")\n",
    "    tt(tables_path +'\\\\B0\\\\B0_1\\\\RESULTS', tables_path + '\\\\B0\\\\help_tables', 'B0_1_ready' + str(i) + '.csv')\n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B0\\\\help_tables\\\\B0_1_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"STD\"]/10000\n",
    "    df = df.merge(df1[[\"COUNTRY\", rasters_si[i]]], on = \"COUNTRY\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"STD\"], axis=1, inplace=True)\n",
    "\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\B0_1_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## B0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:29<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "\n",
    "# Creating SI rasters which satisfy the constraint:\n",
    "# 1) max SI across all crops >= 0.1 (suitable cell for agriculture)\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = Raster(rasters_si[i]) * Raster(cutoff_constraint)\n",
    "    Float(out).save(tables_path + '\\\\B0\\\\B0_2\\\\rasters_si\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [29:50<00:00, 39.78s/it]\n"
     ]
    }
   ],
   "source": [
    "env.workspace = tables_path + '\\\\B0\\\\B0_2\\\\rasters_si\\\\'\n",
    "\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[0],\n",
    "                        tables_path +'\\\\B0\\\\B0_2\\\\RESULTS', \"DATA\", \"STD\")\n",
    "tt(tables_path +'\\\\B0\\\\B0_2\\\\RESULTS', tables_path + '\\\\B0\\\\help_tables', 'B0_2_ready.csv')\n",
    "\n",
    "df = pd.read_csv(tables_path + \"\\\\B0\\\\help_tables\\\\B0_2_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"STD\"]/10000\n",
    "\n",
    "for i in tqdm(range(1, 46)):\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[i],\n",
    "                        tables_path +'\\\\B0\\\\B0_2\\\\RESULTS', \"DATA\", \"STD\")\n",
    "    tt(tables_path +'\\\\B0\\\\B0_2\\\\RESULTS', tables_path + '\\\\B0\\\\help_tables', 'B0_2_ready' + str(i) + '.csv')\n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B0\\\\help_tables\\\\B0_2_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"STD\"]/10000\n",
    "    df = df.merge(df1[[\"COUNTRY\", rasters_si[i]]], on = \"COUNTRY\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"STD\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\B0_2_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## B1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing weights\n",
    "\n",
    "csi_max_among_all_cells = Raster(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')\n",
    "sum_of_maxcsi = ZonalStatistics(regions_shape_path, VAR, csi_max_among_all_cells, \"SUM\", \"DATA\")\n",
    "w_s = Raster(csi_max_among_all_cells) / Raster(sum_of_maxcsi)\n",
    "\n",
    "# Adjusting SI rasters with weights \n",
    "\n",
    "env.workspace = dtb_path\n",
    "for i in range(len(rasters_si)):\n",
    "    out = Raster(rasters_si[i]) * Raster(w_s)\n",
    "    out.save(tables_path + '\\\\B1\\\\B1_1\\\\rasters_si\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\B1\\\\B1_1\\\\rasters_si\\\\'\n",
    "\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[0],\n",
    "                        tables_path +'\\\\B1\\\\B1_1\\\\RESULTS', \"DATA\", \"STD\")\n",
    "tt(tables_path +'\\\\B1\\\\B1_1\\\\RESULTS', tables_path + '\\\\B1\\\\help_tables', 'B1_1_ready.csv')\n",
    "\n",
    "df = pd.read_csv(tables_path + \"\\\\B1\\\\help_tables\\\\B1_1_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"STD\"]/10000\n",
    "\n",
    "for i in tqdm(range(1, 46)):\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[i],\n",
    "                        tables_path +'\\\\B1\\\\B1_1\\\\RESULTS', \"DATA\", \"STD\")\n",
    "    tt(tables_path +'\\\\B1\\\\B1_1\\\\RESULTS', tables_path + '\\\\B1\\\\help_tables', 'B1_1_ready' + str(i) + '.csv')\n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B1\\\\help_tables\\\\B1_1_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"STD\"]/10000\n",
    "    df = df.merge(df1[[\"REGIONID\", rasters_si[i]]], on = \"REGIONID\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"STD\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY\\\\B1_1_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## B1b_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing weights\n",
    "\n",
    "csi_max_among_all_cells = Raster(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')\n",
    "sum_of_maxcsi = ZonalStatistics(regions_shape_path, VAR, csi_max_among_all_cells, \"SUM\", \"DATA\")\n",
    "w_s = Raster(csi_max_among_all_cells) / Raster(sum_of_maxcsi)\n",
    "\n",
    "# Adjusting SI rasters with weights \n",
    "\n",
    "env.workspace = dtb_path\n",
    "for i in range(len(rasters_si)):\n",
    "    out = Raster(rasters_si[i]) * Raster(w_s)\n",
    "    out.save(tables_path + '\\\\B1\\\\B1_1\\\\rasters_si\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\B1\\\\B1_1\\\\rasters_si\\\\'\n",
    "sum_w_si = ZonalStatistics(regions_shape_path, VAR, rasters_si[0], \"SUM\", \"DATA\")\n",
    "\n",
    "env.workspace = dtb_path\n",
    "si_minus_sum_w_si = Raster(rasters_si[0]) - Raster(sum_w_si)\n",
    "\n",
    "square = Square(si_minus_sum_w_si)\n",
    "under_root = Raster(w_s) * Raster(square)\n",
    "out = ZonalStatistics(regions_shape_path, VAR, under_root, \"SUM\", \"DATA\")\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, SquareRoot(out),\n",
    "                        tables_path +'\\\\B1\\\\B1b_1\\\\RESULTS', \"DATA\", \"MINIMUM\")\n",
    "\n",
    "tt(tables_path +'\\\\B1\\\\B1b_1\\\\RESULTS', tables_path + '\\\\B1\\\\help_tables', 'B1b_1_ready.csv')\n",
    "\n",
    "df = pd.read_csv(tables_path + \"\\\\B1\\\\help_tables\\\\B1b_1_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"MIN\"]/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 45/45 [1:08:19<00:00, 91.11s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1, 46)):\n",
    "    env.workspace = tables_path + '\\\\B1\\\\B1_1\\\\rasters_si\\\\'\n",
    "    sum_w_si = ZonalStatistics(regions_shape_path, VAR, rasters_si[i], \"SUM\", \"DATA\")\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "    si_minus_sum_w_si = Raster(rasters_si[i]) - Raster(sum_w_si)\n",
    "\n",
    "    square = Square(si_minus_sum_w_si)\n",
    "    under_root = Raster(w_s) * Raster(square)\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, under_root, \"SUM\", \"DATA\")\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, SquareRoot(out),\n",
    "                            tables_path +'\\\\B1\\\\B1b_1\\\\RESULTS', \"DATA\", \"MINIMUM\")\n",
    "\n",
    "    tt(tables_path +'\\\\B1\\\\B1b_1\\\\RESULTS', tables_path + '\\\\B1\\\\help_tables', 'B1b_1_ready' + str(i) + '.csv')\n",
    "\n",
    "    \n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B1\\\\help_tables\\\\B1b_1_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"MIN\"]/10000\n",
    "    df = df.merge(df1[[\"COUNTRY\", rasters_si[i]]], on = \"COUNTRY\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"MIN\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\B1b_1_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## B1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computing weights\n",
    "\n",
    "csi_max_among_all_cells = Raster(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')\n",
    "sum_of_maxcsi = ZonalStatistics(regions_shape_path, VAR, csi_max_among_all_cells, \"SUM\", \"DATA\")\n",
    "w_s = Raster(csi_max_among_all_cells) / Raster(sum_of_maxcsi)\n",
    "\n",
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "\n",
    "# Creating SI rasters which satisfy the constraint and are multiplied by weights:\n",
    "# 1) max SI across all crops >= 0.1 (suitable cell for agriculture)\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = Raster(rasters_si[i]) * Raster(cutoff_constraint) * Raster(w_s)\n",
    "    Float(out).save(tables_path + '\\\\B1\\\\B1_2\\\\rasters_si\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\B1\\\\B1_2\\\\rasters_si\\\\'\n",
    "\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[0],\n",
    "                        tables_path +'\\\\B1\\\\B1_2\\\\RESULTS', \"DATA\", \"STD\")\n",
    "tt(tables_path +'\\\\B1\\\\B1_2\\\\RESULTS', tables_path + '\\\\B1\\\\help_tables', 'B1_2_ready.csv')\n",
    "\n",
    "df = pd.read_csv(tables_path + \"\\\\B1\\\\help_tables\\\\B1_2_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"STD\"]/10000\n",
    "\n",
    "for i in tqdm(range(1, 46)):\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[i],\n",
    "                        tables_path +'\\\\B1\\\\B1_2\\\\RESULTS', \"DATA\", \"STD\")\n",
    "    tt(tables_path +'\\\\B1\\\\B1_2\\\\RESULTS', tables_path + '\\\\B1\\\\help_tables', 'B1_2_ready' + str(i) + '.csv')\n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B1\\\\help_tables\\\\B1_2_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"STD\"]/10000\n",
    "    df = df.merge(df1[[\"REGIONID\", rasters_si[i]]], on = \"REGIONID\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"STD\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY\\\\B1_2_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## B1b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:27<00:00,  1.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 45/45 [1:03:44<00:00, 84.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# Computing weights\n",
    "\n",
    "csi_max_among_all_cells = Raster(tables_path + '\\\\A1\\\\A1_1\\\\csi_max')\n",
    "sum_of_maxcsi = ZonalStatistics(regions_shape_path, VAR, csi_max_among_all_cells, \"SUM\", \"DATA\")\n",
    "w_s = Raster(csi_max_among_all_cells) / Raster(sum_of_maxcsi)\n",
    "\n",
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "\n",
    "# Creating SI rasters which satisfy the constraint and are multiplied by weights:\n",
    "# 1) max SI across all crops >= 0.1 (suitable cell for agriculture)\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = Raster(rasters_si[i]) * Raster(cutoff_constraint) * Raster(w_s)\n",
    "    Float(out).save(tables_path + '\\\\B1\\\\B1_2\\\\rasters_si\\\\' + rasters_si[i])\n",
    "\n",
    "    \n",
    "    \n",
    "env.workspace = tables_path + '\\\\B1\\\\B1_2\\\\rasters_si\\\\'\n",
    "sum_w_si = ZonalStatistics(regions_shape_path, VAR, rasters_si[0], \"SUM\", \"DATA\")\n",
    "\n",
    "env.workspace = dtb_path\n",
    "si_minus_sum_w_si = Raster(rasters_si[0]) - Raster(sum_w_si)\n",
    "\n",
    "square = Square(si_minus_sum_w_si)\n",
    "under_root = Raster(w_s) * Raster(square)\n",
    "out = ZonalStatistics(regions_shape_path, VAR, under_root, \"SUM\", \"DATA\")\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, SquareRoot(out),\n",
    "                        tables_path +'\\\\B1\\\\B1b_2\\\\RESULTS', \"DATA\", \"MINIMUM\")\n",
    "tt(tables_path +'\\\\B1\\\\B1b_2\\\\RESULTS', tables_path + '\\\\B1\\\\help_tables', 'B1b_2_ready.csv')\n",
    "df = pd.read_csv(tables_path + \"\\\\B1\\\\help_tables\\\\B1b_2_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"MIN\"]/10000\n",
    "\n",
    "\n",
    "for i in tqdm(range(1, 46)):\n",
    "    env.workspace = tables_path + '\\\\B1\\\\B1_2\\\\rasters_si\\\\'\n",
    "    sum_w_si = ZonalStatistics(regions_shape_path, VAR, rasters_si[i], \"SUM\", \"DATA\")\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "    si_minus_sum_w_si = Raster(rasters_si[i]) - Raster(sum_w_si)\n",
    "\n",
    "    square = Square(si_minus_sum_w_si)\n",
    "    under_root = Raster(w_s) * Raster(square)\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, under_root, \"SUM\", \"DATA\")\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, SquareRoot(out),\n",
    "                            tables_path +'\\\\B1\\\\B1b_2\\\\RESULTS', \"DATA\", \"MINIMUM\")\n",
    "\n",
    "    tt(tables_path +'\\\\B1\\\\B1b_2\\\\RESULTS', tables_path + '\\\\B1\\\\help_tables', 'B1b_2_ready' + str(i) + '.csv')\n",
    "\n",
    "    \n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B1\\\\help_tables\\\\B1b_2_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"MIN\"]/10000\n",
    "    df = df.merge(df1[[\"COUNTRY\", rasters_si[i]]], on = \"COUNTRY\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"MIN\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\B1b_2_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## B2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rasters_hyde[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = hyde_path\n",
    "\n",
    "# Computing weights\n",
    "\n",
    "pop_dens = rasters_hyde[6]\n",
    "sum_of_popdens = ZonalStatistics(regions_shape_path, VAR, pop_dens, \"SUM\", \"DATA\")\n",
    "w_s = Raster(pop_dens) / Raster(sum_of_popdens)\n",
    "\n",
    "# Adjusting SI rasters with weights \n",
    "\n",
    "env.workspace = dtb_path\n",
    "for i in range(len(rasters_si)):\n",
    "    out = Raster(rasters_si[i]) * Raster(w_s)\n",
    "    out.save(tables_path + '\\\\B2\\\\B2_1\\\\rasters_si\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\B2\\\\B2_1\\\\rasters_si\\\\'\n",
    "\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[0],\n",
    "                        tables_path +'\\\\B2\\\\B2_1\\\\RESULTS', \"DATA\", \"STD\")\n",
    "tt(tables_path +'\\\\B2\\\\B2_1\\\\RESULTS', tables_path + '\\\\B2\\\\help_tables', 'B2_1_ready.csv')\n",
    "\n",
    "df = pd.read_csv(tables_path + \"\\\\B2\\\\help_tables\\\\B2_1_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"STD\"]/10000\n",
    "\n",
    "for i in tqdm(range(1, 46)):\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[i],\n",
    "                        tables_path +'\\\\B2\\\\B2_1\\\\RESULTS', \"DATA\", \"STD\")\n",
    "    tt(tables_path +'\\\\B2\\\\B2_1\\\\RESULTS', tables_path + '\\\\B2\\\\help_tables', 'B2_1_ready' + str(i) + '.csv')\n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B2\\\\help_tables\\\\B2_1_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"STD\"]/10000\n",
    "    df = df.merge(df1[[\"REGIONID\", rasters_si[i]]], on = \"REGIONID\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"STD\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY\\\\B2_1_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2b_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'popd_1500AD.asc.tif'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = hyde_path\n",
    "rasters_hyde[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.workspace = hyde_path\n",
    "\n",
    "# Computing weights\n",
    "\n",
    "pop_dens = rasters_hyde[6]\n",
    "sum_of_popdens = ZonalStatistics(regions_shape_path, VAR, pop_dens, \"SUM\", \"DATA\")\n",
    "w_s = Raster(pop_dens) / Raster(sum_of_popdens)\n",
    "\n",
    "# Adjusting SI rasters with weights \n",
    "\n",
    "env.workspace = dtb_path\n",
    "for i in range(len(rasters_si)):\n",
    "    out = Raster(rasters_si[i]) * Raster(w_s)\n",
    "    out.save(tables_path + '\\\\B2\\\\B2_1\\\\rasters_si\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\B2\\\\B2_1\\\\rasters_si\\\\'\n",
    "sum_w_si = ZonalStatistics(regions_shape_path, VAR, rasters_si[0], \"SUM\", \"DATA\")\n",
    "\n",
    "env.workspace = dtb_path\n",
    "si_minus_sum_w_si = Raster(rasters_si[0]) - Raster(sum_w_si)\n",
    "\n",
    "square = Square(si_minus_sum_w_si)\n",
    "under_root = Raster(w_s) * Raster(square)\n",
    "out = ZonalStatistics(regions_shape_path, VAR, under_root, \"SUM\", \"DATA\")\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, SquareRoot(out),\n",
    "                        tables_path +'\\\\B2\\\\B2b_1\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "\n",
    "tt(tables_path +'\\\\B2\\\\B2b_1\\\\RESULTS', tables_path + '\\\\B2\\\\help_tables', 'B2b_1_ready.csv')\n",
    "\n",
    "df = pd.read_csv(tables_path + \"\\\\B2\\\\help_tables\\\\B2b_1_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"MAX\"]/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 45/45 [1:31:14<00:00, 121.66s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1, 46)):\n",
    "    env.workspace = tables_path + '\\\\B2\\\\B2_1\\\\rasters_si\\\\'\n",
    "    sum_w_si = ZonalStatistics(regions_shape_path, VAR, rasters_si[i], \"SUM\", \"DATA\")\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "    si_minus_sum_w_si = Raster(rasters_si[i]) - Raster(sum_w_si)\n",
    "\n",
    "    square = Square(si_minus_sum_w_si)\n",
    "    under_root = Raster(w_s) * Raster(square)\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, under_root, \"SUM\", \"DATA\")\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, SquareRoot(out),\n",
    "                            tables_path +'\\\\B2\\\\B2b_1\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "\n",
    "    tt(tables_path +'\\\\B2\\\\B2b_1\\\\RESULTS', tables_path + '\\\\B2\\\\help_tables', 'B2b_1_ready' + str(i) + '.csv')\n",
    "\n",
    "    \n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B2\\\\help_tables\\\\B2b_1_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"MAX\"]/10000\n",
    "    df = df.merge(df1[[\"COUNTRY\", rasters_si[i]]], on = \"COUNTRY\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"MAX\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\B2b_1_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## B2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = hyde_path\n",
    "\n",
    "# Computing weights\n",
    "\n",
    "pop_dens = rasters_hyde[6]\n",
    "sum_of_popdens = ZonalStatistics(regions_shape_path, VAR, pop_dens, \"SUM\", \"DATA\")\n",
    "w_s = Raster(pop_dens) / Raster(sum_of_popdens)\n",
    "\n",
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "\n",
    "# Creating SI rasters which satisfy the constraint and are multiplied by weights:\n",
    "# 1) max SI across all crops >= 0.1 (suitable cell for agriculture)\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = Raster(rasters_si[i]) * Raster(cutoff_constraint) * Raster(w_s)\n",
    "    Float(out).save(tables_path + '\\\\B2\\\\B2_2\\\\rasters_si\\\\' + rasters_si[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = tables_path + '\\\\B2\\\\B2_2\\\\rasters_si\\\\'\n",
    "\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[0],\n",
    "                        tables_path +'\\\\B2\\\\B2_2\\\\RESULTS', \"DATA\", \"STD\")\n",
    "tt(tables_path +'\\\\B2\\\\B2_2\\\\RESULTS', tables_path + '\\\\B2\\\\help_tables', 'B2_2_ready.csv')\n",
    "\n",
    "df = pd.read_csv(tables_path + \"\\\\B2\\\\help_tables\\\\B2_2_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"STD\"]/10000\n",
    "\n",
    "for i in tqdm(range(1, 46)):\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, rasters_si[i],\n",
    "                        tables_path +'\\\\B2\\\\B2_2\\\\RESULTS', \"DATA\", \"STD\")\n",
    "    tt(tables_path +'\\\\B2\\\\B2_2\\\\RESULTS', tables_path + '\\\\B2\\\\help_tables', 'B2_2_ready' + str(i) + '.csv')\n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B2\\\\help_tables\\\\B2_2_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"STD\"]/10000\n",
    "    df = df.merge(df1[[\"REGIONID\", rasters_si[i]]], on = \"REGIONID\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"STD\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY\\\\B2_2_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:52<00:00,  1.14s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 45/45 [1:03:04<00:00, 84.09s/it]\n"
     ]
    }
   ],
   "source": [
    "env.workspace = hyde_path\n",
    "\n",
    "# Computing weights\n",
    "\n",
    "pop_dens = rasters_hyde[6]\n",
    "sum_of_popdens = ZonalStatistics(regions_shape_path, VAR, pop_dens, \"SUM\", \"DATA\")\n",
    "w_s = Raster(pop_dens) / Raster(sum_of_popdens)\n",
    "\n",
    "env.workspace = dtb_path\n",
    "\n",
    "# Defining maximum SI in each cell\n",
    "max_si_all_cells = Float(arcpy.sa.CellStatistics(rasters_si, 'MAXIMUM', 'DATA'))\n",
    "# Avoiding cells where maximum SI <= 0.1\n",
    "cutoff_constraint = SetNull(max_si_all_cells, 1, \"VALUE <= 1000\")\n",
    "\n",
    "# Creating SI rasters which satisfy the constraint and are multiplied by weights:\n",
    "# 1) max SI across all crops >= 0.1 (suitable cell for agriculture)\n",
    "\n",
    "for i in tqdm(range(46)):\n",
    "    out = Raster(rasters_si[i]) * Raster(cutoff_constraint) * Raster(w_s)\n",
    "    Float(out).save(tables_path + '\\\\B2\\\\B2_2\\\\rasters_si\\\\' + rasters_si[i])\n",
    "\n",
    "\n",
    "env.workspace = tables_path + '\\\\B2\\\\B2_2\\\\rasters_si\\\\'\n",
    "sum_w_si = ZonalStatistics(regions_shape_path, VAR, rasters_si[0], \"SUM\", \"DATA\")\n",
    "\n",
    "env.workspace = dtb_path\n",
    "si_minus_sum_w_si = Raster(rasters_si[0]) - Raster(sum_w_si)\n",
    "\n",
    "square = Square(si_minus_sum_w_si)\n",
    "under_root = Raster(w_s) * Raster(square)\n",
    "out = ZonalStatistics(regions_shape_path, VAR, under_root, \"SUM\", \"DATA\")\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, SquareRoot(out),\n",
    "                        tables_path +'\\\\B2\\\\B2b_2\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +'\\\\B2\\\\B2b_2\\\\RESULTS', tables_path + '\\\\B2\\\\help_tables', 'B2b_2_ready.csv')\n",
    "df = pd.read_csv(tables_path + \"\\\\B2\\\\help_tables\\\\B2b_2_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[rasters_si[0]] = df[\"MAX\"]/10000\n",
    "\n",
    "\n",
    "for i in tqdm(range(1, 46)):\n",
    "    env.workspace = tables_path + '\\\\B2\\\\B2_2\\\\rasters_si\\\\'\n",
    "    sum_w_si = ZonalStatistics(regions_shape_path, VAR, rasters_si[i], \"SUM\", \"DATA\")\n",
    "\n",
    "    env.workspace = dtb_path\n",
    "    si_minus_sum_w_si = Raster(rasters_si[i]) - Raster(sum_w_si)\n",
    "\n",
    "    square = Square(si_minus_sum_w_si)\n",
    "    under_root = Raster(w_s) * Raster(square)\n",
    "    out = ZonalStatistics(regions_shape_path, VAR, under_root, \"SUM\", \"DATA\")\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, SquareRoot(out),\n",
    "                            tables_path +'\\\\B2\\\\B2b_2\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "\n",
    "    tt(tables_path +'\\\\B2\\\\B2b_2\\\\RESULTS', tables_path + '\\\\B2\\\\help_tables', 'B2b_2_ready' + str(i) + '.csv')\n",
    "\n",
    "    \n",
    "    df1 = pd.read_csv(tables_path + \"\\\\B2\\\\help_tables\\\\B2b_2_ready\" + str(i) + \".csv\", decimal = \",\", sep =\";\")\n",
    "    df1[rasters_si[i]] = df1[\"MAX\"]/10000\n",
    "    df = df.merge(df1[[\"COUNTRY\", rasters_si[i]]], on = \"COUNTRY\")\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"MAX\"], axis=1, inplace=True)\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\B2b_2_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [15:14<00:00, 33.86s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\D1_READY.csv<h2>Messages</h2>Start Time: 7 июня 2023 г. 2:51:13<br/>Succeeded at 7 июня 2023 г. 2:51:13 (Elapsed Time: 0,10 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\D1_READY.csv'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = fao_prod_path\n",
    "\n",
    "sum_across_crops = Float(arcpy.sa.CellStatistics(rasters_fao_prod, 'SUM', 'DATA'))\n",
    "denumerator = ZonalStatistics(regions_shape_path, VAR, sum_across_crops, \"SUM\", \"DATA\")\n",
    "\n",
    "for i in tqdm(range(len(rasters_fao_prod))):\n",
    "    numerator = ZonalStatistics(regions_shape_path, VAR, rasters_fao_prod[i], \"SUM\", \"DATA\")\n",
    "    frac_score = Raster(numerator) / Raster(denumerator)\n",
    "    sq = Square(frac_score)\n",
    "    Float(sq).save(tables_path +'\\\\D1\\\\frac_squared\\\\' + rasters_fao_prod[i])\n",
    "    \n",
    "    \n",
    "env.workspace = tables_path + '\\\\D1\\\\frac_squared\\\\'\n",
    "\n",
    "out = Float(arcpy.sa.CellStatistics(rasters_fao_prod, 'SUM', 'DATA'))\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, 1-Float(out),\n",
    "                        tables_path +'\\\\D1\\\\RESULTS', \"DATA\", \"MAXIMUM\")\n",
    "tt(tables_path +'\\\\D1\\\\RESULTS', tables_path + '\\\\READY_country_level', 'D1_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Correct order of files and names for E indices\n",
    "\n",
    "indexE_rasters_hyde = ['popd_1500AD.asc.tif',\n",
    " 'popd_1700AD.asc.tif', 'cropland1500AD.asc.tif',\n",
    " 'cropland1700AD.asc.tif', 'tot_rainfed1500AD.asc.tif',\n",
    " 'tot_rainfed1700AD.asc.tif', 'rf_rice1500AD.asc.tif',\n",
    " 'rf_rice1700AD.asc.tif', 'rf_norice1500AD.asc.tif',\n",
    " 'rf_norice1700AD.asc.tif', 'grazing1500AD.asc.tif',\n",
    " 'grazing1700AD.asc.tif', 'rangeland1500AD.asc.tif',\n",
    " 'rangeland1700AD.asc.tif', 'pasture1500AD.asc.tif',\n",
    " 'pasture1700AD.asc.tif']\n",
    "\n",
    "indexE_names = [\"E0a\", \"E0b\", \"E1a\", \"E1b\", \"E2a\", \"E2b\", \"E3a\", \"E3b\", \"E4a\", \"E4b\", \"E5a\", \"E5b\", \"E6a\", \"E6b\", \"E7a\", \"E7b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [08:03<00:00, 32.25s/it]\n"
     ]
    }
   ],
   "source": [
    "env.workspace = hyde_path\n",
    "\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, indexE_rasters_hyde[0],\n",
    "                        tables_path +'\\\\E\\\\RESULTS', \"DATA\", \"MEAN\")\n",
    "tt(tables_path +'\\\\E\\\\RESULTS', tables_path + '\\\\E\\\\help_tables', 'E0_ready.csv')\n",
    "\n",
    "\n",
    "df = pd.read_csv(tables_path + \"\\\\E\\\\help_tables\\\\E0_ready.csv\", decimal = \",\", sep =\";\")\n",
    "df[indexE_names[0]] = df[\"MEAN\"]\n",
    "for i in tqdm(range(1, 16)):\n",
    "    arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, indexE_rasters_hyde[i],\n",
    "                        tables_path +'\\\\E\\\\RESULTS', \"DATA\", \"MEAN\")\n",
    "    tt(tables_path +'\\\\E\\\\RESULTS', tables_path + '\\\\E\\\\help_tables', 'E' + str(i) + '_ready.csv')\n",
    "    df1 = pd.read_csv(tables_path + '\\\\E\\\\help_tables\\\\E' + str(i) + '_ready.csv', decimal = \",\", sep =\";\")\n",
    "    df1[indexE_names[i]] = df1[\"MEAN\"]\n",
    "    df = df.merge(df1[[\"COUNTRY\", indexE_names[i]]], on = \"COUNTRY\", how='outer')\n",
    "    \n",
    "df.drop([\"OID_\", \"ZONE_CODE\", \"MEAN\"], axis=1, inplace=True)\n",
    "\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\E_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1a, F1b, F2, F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.Dissolve_management(regions_shape_path, countries_shape_path, \"COUNTRY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.workspace = trade_path\n",
    "trade_points = ['trade_1700_full.shp', 'trade_1300.shp', 'ancient_ports.shp', 'romanroads_points.shp']\n",
    "indexF_names = [\"F1a\", \"F1b\", \"F2\", \"F3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersecting points and shape files of regions\n",
    "\n",
    "for i in range(4):\n",
    "    target_features = countries_shape_path\n",
    "    join_features = trade_points[i]\n",
    "    out_feature_class =  tables_path + '\\\\F\\\\help_tables\\\\F' + str(i)\n",
    "\n",
    "    arcpy.analysis.SpatialJoin(target_features, join_features, out_feature_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table\n",
    "\n",
    "fc = tables_path + '\\\\F\\\\help_tables\\\\F0.shp'\n",
    "fields = ['COUNTRY', 'Join_Count']\n",
    "res = []\n",
    "with arcpy.da.SearchCursor(fc, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        res.append(row)\n",
    "df = pd.DataFrame(res, columns = ['COUNTRY', indexF_names[0]])\n",
    "\n",
    "for i in range(1, 4): \n",
    "    fc = tables_path + '\\\\F\\\\help_tables\\\\F' + str(i) + '.shp'\n",
    "    fields = ['COUNTRY', 'Join_Count']\n",
    "    res = []\n",
    "    with arcpy.da.SearchCursor(fc, fields) as cursor:\n",
    "        for row in cursor:\n",
    "            res.append(row)\n",
    "    df = df.merge(pd.DataFrame(res, columns = ['COUNTRY', indexF_names[i]]), on = 'COUNTRY')\n",
    "\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\F1-F3_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F4a, F4b, F5, F6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.workspace = trade_path\n",
    "trade_points = ['trade_1700_full.shp', 'trade_1300.shp', 'ancient_ports.shp', 'romanroads_points.shp']\n",
    "indexF_names = [\"F4a\", \"F4b\", \"F5\", \"F6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\F\\centroids.shp<h2>Messages</h2>Start Time: 11 июня 2023 г. 23:31:35<br/>Succeeded at 11 июня 2023 г. 23:31:40 (Elapsed Time: 5,37 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\F\\\\centroids.shp'>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Feature Layer with centroids of regions\n",
    "\n",
    "inFeat = countries_shape_path\n",
    "outFeat = tables_path + '\\\\F\\\\centroids'\n",
    "arcpy.FeatureToPoint_management(inFeat, outFeat, \"CENTROID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = tables_path + '\\\\F\\\\centroids.shp'\n",
    "near_features = trade_points[0]\n",
    "arcpy.analysis.Near(in_features, near_features, method = 'GEODESIC')\n",
    "\n",
    "fc = tables_path + '\\\\F\\\\centroids.shp'\n",
    "fields = ['COUNTRY', 'NEAR_DIST']\n",
    "res = []\n",
    "with arcpy.da.SearchCursor(fc, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        res.append(row)\n",
    "df = pd.DataFrame(res, columns = ['COUNTRY', indexF_names[0]])\n",
    "\n",
    "\n",
    "for i in range(1, 4):\n",
    "    near_features = trade_points[i]\n",
    "    arcpy.analysis.Near(in_features, near_features, method = 'GEODESIC')\n",
    "    \n",
    "    fc = tables_path + '\\\\F\\\\centroids.shp'\n",
    "    fields = ['COUNTRY', 'NEAR_DIST']\n",
    "    res = []\n",
    "    with arcpy.da.SearchCursor(fc, fields) as cursor:\n",
    "        for row in cursor:\n",
    "            res.append(row)\n",
    "    df = df.merge(pd.DataFrame(res, columns = ['COUNTRY', indexF_names[i]]), on = 'COUNTRY')\n",
    "\n",
    "# Making distance_unit = 'kilometers'    \n",
    "df[indexF_names] = df[indexF_names]/1000\n",
    "\n",
    "# Saving\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\F4-F6_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F7a, F7b, F8, F9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.workspace = trade_path\n",
    "trade_points = ['trade_1700_full.shp', 'trade_1300.shp', 'ancient_ports.shp', 'romanroads_points.shp']\n",
    "indexF_names = [\"F7a\", \"F7b\", \"F8\", \"F9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_source_data = trade_path + '\\\\' + trade_points[0]\n",
    "in_cost_raster = r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Human Mobility Index\\Human Mobility Index\\HMISea.tif\"\n",
    "cost_dist = CostDistance(in_source_data, in_cost_raster)\n",
    "\n",
    "in_point_features = tables_path + '\\\\F\\\\centroids.shp'\n",
    "in_raster = cost_dist\n",
    "out_point_features = tables_path + '\\\\F\\\\' + indexF_names[0] + '.shp'\n",
    "ExtractValuesToPoints(in_point_features, in_raster, out_point_features)\n",
    "\n",
    "fc = out_point_features\n",
    "fields = ['COUNTRY', 'RASTERVALU']\n",
    "res = []\n",
    "with arcpy.da.SearchCursor(fc, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        res.append(row)\n",
    "df = pd.DataFrame(res, columns = ['COUNTRY', indexF_names[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    in_source_data = trade_path + '\\\\' + trade_points[i]\n",
    "    in_cost_raster = r\"C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Human Mobility Index\\Human Mobility Index\\HMISea.tif\"\n",
    "    cost_dist = CostDistance(in_source_data, in_cost_raster)\n",
    "    \n",
    "    in_point_features = tables_path + '\\\\F\\\\centroids.shp'\n",
    "    in_raster = cost_dist\n",
    "    out_point_features = tables_path + '\\\\F\\\\' + indexF_names[i] + '.shp'\n",
    "    ExtractValuesToPoints(in_point_features, in_raster, out_point_features)\n",
    "    \n",
    "    fc = out_point_features\n",
    "    fields = ['COUNTRY', 'RASTERVALU']\n",
    "    res = []\n",
    "    with arcpy.da.SearchCursor(fc, fields) as cursor:\n",
    "        for row in cursor:\n",
    "            res.append(row)\n",
    "    df = df.merge(pd.DataFrame(res, columns = ['COUNTRY', indexF_names[i]]), on = 'COUNTRY')\n",
    "\n",
    "# Making distance_unit = 'kilometers'    \n",
    "df[indexF_names] = df[indexF_names]/1000\n",
    "\n",
    "# Saving\n",
    "output_path = tables_path + '\\\\READY_country_level\\\\F7-F9_READY.xlsx'\n",
    "df.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.workspace = hmi_path\n",
    "rasters_hmi = arcpy.ListRasters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\hmi_resampled.tif<h2>Messages</h2>Start Time: 12 июня 2023 г. 0:19:56<br/>Building Pyramids...<br/>Succeeded at 12 июня 2023 г. 0:22:24 (Elapsed Time: 2 minutes 28 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\hmi_resampled.tif'>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.Resample_management(rasters_hmi[0], tables_path + \"\\\\hmi_resampled.tif\", \"1000\", \"BILINEAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_numpy(raster):\n",
    "    descData = arcpy.Describe(raster)\n",
    "    cellSize = descData.meanCellHeight\n",
    "    extent = descData.Extent\n",
    "    spatialReference = descData.spatialReference\n",
    "    pnt = arcpy.Point(extent.XMin,extent.YMin)\n",
    "    return arcpy.RasterToNumPyArray(raster, lower_left_corner=pnt, nodata_to_value= -5)\n",
    "\n",
    "X = raster_to_numpy(tables_path + \"\\\\hmi_resampled.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11867/11867 [44:08<00:00,  4.48it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_hmi = np.zeros((X.shape[0], X.shape[1]))\n",
    "\n",
    "for i in tqdm(range(1, X.shape[0]-1)):\n",
    "    for j in range(1, X.shape[1]-1):\n",
    "        if X[i][j] != -5:\n",
    "            n = 0\n",
    "            S = 0\n",
    "            if X[i-1][j-1] != -5:\n",
    "                n+=1\n",
    "                S += 1.41421 * (X[i-1][j-1] + X[i][j])/2\n",
    "            elif X[i-1][j+1] != -5:\n",
    "                n+=1\n",
    "                S += 1.41421 * (X[i-1][j+1] + X[i][j])/2\n",
    "            elif X[i+1][j-1] != -5:\n",
    "                n+=1\n",
    "                S += 1.41421 * (X[i+1][j-1] + X[i][j])/2\n",
    "            elif X[i-1][j+1] != -5:\n",
    "                n+=1\n",
    "                S += 1.41421 * (X[i-1][j+1] + X[i][j])/2\n",
    "            elif X[i-1][j] != -5:\n",
    "                n+=1\n",
    "                S += 1 * (X[i-1][j] + X[i][j])/2\n",
    "            elif X[i+1][j] != -5:\n",
    "                n+=1\n",
    "                S += 1 * (X[i+1][j] + X[i][j])/2\n",
    "            elif X[i][j-1] != -5:\n",
    "                n+=1\n",
    "                S += 1 * (X[i][j-1] + X[i][j])/2\n",
    "            elif X[i][j+1] != -5:\n",
    "                n+=1\n",
    "                S += 1 * (X[i][j+1] + X[i][j])/2\n",
    "\n",
    "            if n>0:\n",
    "                avg_hmi[i][j] = S/n\n",
    "                \n",
    "avg_hmi = avg_hmi.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11869, 40075)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_hmi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument in_array: A two or three dimensional NumPy array is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-262-c44d7338e63a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewRaster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy_to_raster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtables_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\avg_hmi.tif\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m#out.save(tables_path + \"\\\\avg_hmi.tif\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, out,\n",
      "\u001b[1;32m<ipython-input-262-c44d7338e63a>\u001b[0m in \u001b[0;36mnumpy_to_raster\u001b[1;34m(numpy_array)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mspatialReference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatialReference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXMin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mextent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYMin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mnewRaster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumPyArrayToRaster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpnt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcellSize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcellSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_to_nodata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDefineProjection_management\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewRaster\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspatialReference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewRaster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\__init__.py\u001b[0m in \u001b[0;36mNumPyArrayToRaster\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2419\u001b[0m          \u001b[0mmdinfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2420\u001b[0m        The json or string that defines the multidimensional information\"\"\"\n\u001b[1;32m-> 2421\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_NumPyArrayToRaster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2423\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mGetImageEXIFProperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Argument in_array: A two or three dimensional NumPy array is required."
     ]
    }
   ],
   "source": [
    "def numpy_to_raster(numpy_array):\n",
    "    descData = arcpy.Describe(tables_path + \"\\\\hmi_resampled.tif\")\n",
    "    cellSize = descData.meanCellHeight\n",
    "    extent = descData.Extent\n",
    "    spatialReference = descData.spatialReference\n",
    "    pnt = arcpy.Point(extent.XMin,extent.YMin)\n",
    "    newRaster = arcpy.NumPyArrayToRaster(numpy_array,pnt,cellSize,cellSize, value_to_nodata = 0)\n",
    "    arcpy.DefineProjection_management(newRaster,spatialReference)\n",
    "    return newRaster\n",
    "\n",
    "out = numpy_to_raster(tables_path + \"\\\\avg_hmi.tif\")\n",
    "#out.save(tables_path + \"\\\\avg_hmi.tif\")\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, out,\n",
    "                        tables_path +'\\\\G1\\\\RESULTS', \"DATA\", \"MEAN\")\n",
    "tt(tables_path +'\\\\G1\\\\RESULTS', tables_path + '\\\\READY_country_level', 'G1_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## G1_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('kernel_G.txt', 'w') as f:\n",
    "    f.write('3 3\\n0.653762 0.46228 0.653762\\n0.46228 4.46417 0.46228\\n0.653762 0.46228 0.653762')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.workspace = hmi_path\n",
    "rasters_hmi = arcpy.ListRasters()\n",
    "OutRas = FocalStatistics(rasters_hmi[0], NbrWeight('kernel_G.txt'), \"SUM\", \"NODATA\")\n",
    "out = Raster(OutRas) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\G1_b_READY.csv<h2>Messages</h2>Start Time: 12 июня 2023 г. 0:03:53<br/>Succeeded at 12 июня 2023 г. 0:03:53 (Elapsed Time: 0,17 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\G1_b_READY.csv'>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.gp.ZonalStatisticsAsTable_sa(countries_shape_path, VAR, out,\n",
    "                        tables_path +'\\\\G1\\\\RESULTS', \"DATA\", \"MEAN\")\n",
    "tt(tables_path +'\\\\G1\\\\RESULTS', tables_path + '\\\\READY_country_level', 'G1_b_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\hmisea_resampled.tif<h2>Messages</h2>Start Time: 8 мая 2023 г. 12:05:56<br/>Building Pyramids...<br/>Succeeded at 8 мая 2023 г. 12:08:12 (Elapsed Time: 2 minutes 16 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\hmisea_resampled.tif'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.workspace = hmi_path\n",
    "rasters_hmi = arcpy.ListRasters()\n",
    "arcpy.Resample_management(rasters_hmi[1], tables_path + \"\\\\hmisea_resampled.tif\", \"1000\", \"BILINEAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_numpy(raster):\n",
    "    descData = arcpy.Describe(raster)\n",
    "    cellSize = descData.meanCellHeight\n",
    "    extent = descData.Extent\n",
    "    spatialReference = descData.spatialReference\n",
    "    pnt = arcpy.Point(extent.XMin,extent.YMin)\n",
    "    return arcpy.RasterToNumPyArray(raster, lower_left_corner=pnt, nodata_to_value= -5)\n",
    "\n",
    "X = raster_to_numpy(tables_path + \"\\\\hmisea_resampled.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11867/11867 [38:22<00:00,  5.15it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_hmi = np.zeros((X.shape[0], X.shape[1]))\n",
    "\n",
    "for i in tqdm(range(1, X.shape[0]-1)):\n",
    "    for j in range(1, X.shape[1]-1):\n",
    "        if X[i][j] != -5:\n",
    "            n = 0\n",
    "            S = 0\n",
    "            if X[i-1][j-1] != -5:\n",
    "                n+=1\n",
    "                S += 1.41421 * (X[i-1][j-1] + X[i][j])/2\n",
    "            elif X[i-1][j+1] != -5:\n",
    "                n+=1\n",
    "                S += 1.41421 * (X[i-1][j+1] + X[i][j])/2\n",
    "            elif X[i+1][j-1] != -5:\n",
    "                n+=1\n",
    "                S += 1.41421 * (X[i+1][j-1] + X[i][j])/2\n",
    "            elif X[i-1][j+1] != -5:\n",
    "                n+=1\n",
    "                S += 1.41421 * (X[i-1][j+1] + X[i][j])/2\n",
    "            elif X[i-1][j] != -5:\n",
    "                n+=1\n",
    "                S += 1 * (X[i-1][j] + X[i][j])/2\n",
    "            elif X[i+1][j] != -5:\n",
    "                n+=1\n",
    "                S += 1 * (X[i+1][j] + X[i][j])/2\n",
    "            elif X[i][j-1] != -5:\n",
    "                n+=1\n",
    "                S += 1 * (X[i][j-1] + X[i][j])/2\n",
    "            elif X[i][j+1] != -5:\n",
    "                n+=1\n",
    "                S += 1 * (X[i][j+1] + X[i][j])/2\n",
    "\n",
    "            if n>0:\n",
    "                avg_hmi[i][j] = S/n\n",
    "                \n",
    "avg_hmi = avg_hmi.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_raster(numpy_array):\n",
    "    descData = arcpy.Describe(tables_path + \"\\\\hmisea_resampled.tif\")\n",
    "    cellSize = descData.meanCellHeight\n",
    "    extent = descData.Extent\n",
    "    spatialReference = descData.spatialReference\n",
    "    pnt = arcpy.Point(extent.XMin,extent.YMin)\n",
    "    newRaster = arcpy.NumPyArrayToRaster(numpy_array,pnt,cellSize,cellSize, value_to_nodata = 0)\n",
    "    arcpy.DefineProjection_management(newRaster,spatialReference)\n",
    "    return newRaster\n",
    "\n",
    "out = numpy_to_raster(avg_hmi)\n",
    "arcpy.gp.ZonalStatisticsAsTable_sa(regions_shape_path, VAR, out,\n",
    "                        tables_path +'\\\\G2\\\\RESULTS', \"DATA\", \"MEAN\")\n",
    "tt(tables_path +'\\\\G2\\\\RESULTS', tables_path + '\\\\READY', 'G2_READY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## G2_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "OutRas = FocalStatistics(rasters_hmi[1], NbrWeight('kernel_G.txt'), \"SUM\", \"NODATA\")\n",
    "out = Raster(OutRas) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\G2_b_READY.csv<h2>Messages</h2>Start Time: 12 июня 2023 г. 0:06:47<br/>Succeeded at 12 июня 2023 г. 0:06:47 (Elapsed Time: 0,25 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Nikita Gordonov.LAPTOP-72M1R5VQ\\\\OneDrive\\\\Рабочий стол\\\\RA\\\\Nikita indices\\\\READY_country_level\\\\G2_b_READY.csv'>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.gp.ZonalStatisticsAsTable_sa(countries_shape_path, VAR, out,\n",
    "                        tables_path +'\\\\G2\\\\RESULTS', \"DATA\", \"MEAN\")\n",
    "tt(tables_path +'\\\\G2\\\\RESULTS', tables_path + '\\\\READY_country_level', 'G2_b_READY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Share of cells that are suitable for agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\B0_1_READY.xlsx')\n",
    "df1 = pd.read_excel(r'C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\B0_2_READY.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>COUNT_x</th>\n",
       "      <th>COUNT_y</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>1320</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.955303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>10781</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>0.946202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>109</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>64</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Virgin Islands, U.S.</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>144</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.881944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Wallis and Futuna</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Samoa</td>\n",
       "      <td>33</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    COUNTRY  COUNT_x  COUNT_y     share\n",
       "0                Azerbaijan     1320   1261.0  0.955303\n",
       "1                 Hong Kong       13     13.0  1.000000\n",
       "2                   Nigeria    10781  10201.0  0.946202\n",
       "3               Puerto Rico      109    109.0  1.000000\n",
       "4       Trinidad and Tobago       64     64.0  1.000000\n",
       "..                      ...      ...      ...       ...\n",
       "214  British Virgin Islands        2      1.0  0.500000\n",
       "215    Virgin Islands, U.S.        3      3.0  1.000000\n",
       "216                 Vanuatu      144    127.0  0.881944\n",
       "217       Wallis and Futuna        2      0.0  0.000000\n",
       "218                   Samoa       33     32.0  0.969697\n",
       "\n",
       "[219 rows x 4 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.merge(df1, how= 'left', on ='COUNTRY')\n",
    "data = data[['COUNTRY','COUNT_x', 'COUNT_y']]\n",
    "data.fillna(0, inplace=True)\n",
    "data['share'] = data['COUNT_y']/data['COUNT_x']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['COUNTRY', 'share']].to_excel(r'C:\\Users\\Nikita Gordonov.LAPTOP-72M1R5VQ\\OneDrive\\Рабочий стол\\RA\\Nikita indices\\READY_country_level\\share_of_cells_suitable_for_agriculture.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ['A1_1', 'A1_2', 'A1_3', 'A1_4', \n",
    "           'A2a_1', 'A2a_2', 'A2a_3', 'A2a_4', \n",
    "           'A2b_1', 'A2b_2', 'A2b_3', 'A2b_4',\n",
    "           'A3_1', 'A3_2', 'A3_3', 'A3_4', \n",
    "           'A4_1', 'A4_2', 'A4_3', 'A4_4', \n",
    "           'A5_1', 'A5_2', 'A5_3', 'A5_4', \n",
    "           'D1']\n",
    "df = pd.read_csv(tables_path + '\\\\READY_country_level\\\\' + indices[0] + '_READY.csv', sep=';', decimal=',')\n",
    "df.rename(columns ={'MIN': 'A1_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(indices)):\n",
    "    try: \n",
    "        df1 = pd.read_csv(tables_path + '\\\\READY_country_level\\\\' + indices[i] + '_READY.csv', sep=';', decimal=',')\n",
    "        df1.rename(columns ={'MIN': indices[i], \"MAX\": indices[i]}, inplace=True)\n",
    "        df = df.merge(df1[['COUNTRY', indices[i]]], on='COUNTRY', how='left')\n",
    "    except: \n",
    "        df1 = pd.read_excel(tables_path + '\\\\READY_country_level\\\\' + indices[i] + '_READY.xlsx')\n",
    "        df = df.merge(df1[['COUNTRY', indices[i]]], on='COUNTRY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(tables_path + '\\\\READY_country_level\\\\A1_1-D1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(tables_path + '\\\\READY_country_level\\\\A1_1-D1.xlsx')\n",
    "df1 = pd.read_excel(tables_path + '\\\\READY_country_level\\\\E_READY.xlsx')\n",
    "df = df.merge(df1[['COUNTRY', 'E0a', 'E0b', 'E1a', 'E1b',\n",
    "       'E2a', 'E2b', 'E3a', 'E3b', 'E4a', 'E4b', 'E5a', 'E5b', 'E6a', 'E6b',\n",
    "       'E7a', 'E7b']], on='COUNTRY', how ='left')\n",
    "df1 = pd.read_excel(tables_path + '\\\\READY_country_level\\\\F1-F3_READY.xlsx')\n",
    "df2 = pd.read_excel(tables_path + '\\\\READY_country_level\\\\F4-F6_READY.xlsx')\n",
    "df1 = df1.merge(df2[['COUNTRY', 'F4a', 'F4b', 'F5', 'F6']], on='COUNTRY', how ='left')\n",
    "df3 = pd.read_excel(tables_path + '\\\\READY_country_level\\\\F7-F9_READY.xlsx')\n",
    "df1 = df1.merge(df3[['COUNTRY', 'F7a', 'F7b', 'F8', 'F9']], on='COUNTRY', how ='left')\n",
    "df1.loc[df1[\"COUNTRY\"] == \"Côte d'Ivoire\", \"COUNTRY\"] = \"C_te d'Ivoire\"\n",
    "df1.loc[df1[\"COUNTRY\"] == \"São Tomé and Príncipe\", \"COUNTRY\"] = \"S_o Tom_ and Pr_ncipe\"\n",
    "\n",
    "df = df.merge(df1, on='COUNTRY', how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(tables_path + '\\\\READY_country_level\\\\G1_b_READY.csv', sep=';', decimal=',')\n",
    "df = df.merge(df1[['COUNTRY', 'G1_b']], on='COUNTRY', how ='left')\n",
    "df1 = pd.read_csv(tables_path + '\\\\READY_country_level\\\\G2_b_READY.csv', sep=';', decimal=',')\n",
    "df = df.merge(df1[['COUNTRY', 'G2_b']], on='COUNTRY', how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(tables_path + '\\\\READY_country_level\\\\country-level_indices.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
